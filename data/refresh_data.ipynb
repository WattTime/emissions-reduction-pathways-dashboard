{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e2338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- LIBRARY IMPORTS AND FUNCTION DEFINITIONS ----------------------------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import sys, os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.utils import data_add_moer\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import psycopg2\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "postgres_url = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "\n",
    "def split_or_move_parquet(input_file, output_dir, target_size_mb=40):\n",
    "    \"\"\"\n",
    "    Splits a large Parquet file into ~target_size_mb chunks or moves it directly \n",
    "    to desdired folder if under the threshold.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input parquet file.\n",
    "        output_dir (str): Directory to save chunked (or moved) parquet files.\n",
    "        target_size_mb (int): Approx size limit per chunk in MB.\n",
    "    \"\"\"\n",
    "    input_file = Path(input_file)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_size_mb = input_file.stat().st_size / (1024 * 1024)\n",
    "\n",
    "    # If file is already below threshold, just move it\n",
    "    if file_size_mb <= target_size_mb:\n",
    "        dest_file = output_dir / input_file.name\n",
    "        shutil.move(str(input_file), dest_file)\n",
    "        print(f\"‚úÖ File {input_file.name} was {file_size_mb:.1f} MB, moved to {dest_file}\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚ö° Splitting {input_file.name} ({file_size_mb:.1f} MB)...\")\n",
    "\n",
    "    # Load full Parquet into DataFrame\n",
    "    df = pd.read_parquet(input_file)\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Estimate bytes per row\n",
    "    test_sample = df.iloc[:min(10000, total_rows)]\n",
    "    test_table = pa.Table.from_pandas(test_sample)\n",
    "    pq.write_table(test_table, \"temp.parquet\")\n",
    "    bytes_per_row = os.path.getsize(\"temp.parquet\") / len(test_sample)\n",
    "    os.remove(\"temp.parquet\")\n",
    "\n",
    "    # Rows per chunk\n",
    "    target_bytes = target_size_mb * 1024 * 1024\n",
    "    rows_per_chunk = max(1, int(target_bytes / bytes_per_row))\n",
    "\n",
    "    # Split and write\n",
    "    for i, start in enumerate(range(0, total_rows, rows_per_chunk)):\n",
    "        end = min(start + rows_per_chunk, total_rows)\n",
    "        chunk_df = df.iloc[start:end]\n",
    "        chunk_table = pa.Table.from_pandas(chunk_df)\n",
    "        output_path = output_dir / f\"{input_file.stem}_chunk_{i+1}.parquet\"\n",
    "        pq.write_table(chunk_table, output_path)\n",
    "        size_mb = output_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - Saved {output_path} ({size_mb:.1f} MB, rows {start}‚Äì{end})\")\n",
    "\n",
    "    # Delete original after chunking\n",
    "    input_file.unlink()\n",
    "    print(f\"üóëÔ∏è Deleted original {input_file.name}\")\n",
    "    print(\"‚úÖ Splitting complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete archived data and move recent data into archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script takes CSVs dropped into data/zzz_landing_zone,\n",
    "routes them based on filename, and converts them into Parquet.\n",
    "If the new parquet is larger than 45MB, it will be split into \n",
    "smaller chunks before routing to its destination folder.\n",
    "\n",
    "‚ö†Ô∏è Only processes .csv files\n",
    "\"\"\"\n",
    "\n",
    "input_dir = Path(\"zzz_landing_zone\")\n",
    "output_base = Path(\"statistics\")\n",
    "\n",
    "routing_map = {\n",
    "    \"country_subsector_emissions_statistics\": \"country_subsector_emissions_statistics\",\n",
    "    \"country_subsector_emissions_totals\": \"country_subsector_emissions_totals\",\n",
    "    \"gadm_1_emissions_statistics\": \"gadm_1_emissions_statistics\"\n",
    "}\n",
    "\n",
    "# Ensure output subfolders exist\n",
    "for subfolder in routing_map.values():\n",
    "    (output_base / subfolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process only CSVs\n",
    "for csv_file in input_dir.glob(\"*.csv\"):\n",
    "    print(f\"Converting {csv_file.name}...\")\n",
    "\n",
    "    # Convert CSV ‚Üí Parquet in landing zone\n",
    "    df = pd.read_csv(csv_file)\n",
    "    parquet_file = input_dir / csv_file.with_suffix(\".parquet\").name\n",
    "    df.to_parquet(parquet_file, engine=\"pyarrow\", index=False)\n",
    "    print(f\"‚úÖ Converted {csv_file.name} ‚Üí {parquet_file.name} in landing zone\")\n",
    "\n",
    "    # Delete original CSV\n",
    "    csv_file.unlink()\n",
    "    print(f\"üóëÔ∏è Deleted original CSV: {csv_file.name}\")\n",
    "\n",
    "    # Route Parquet into correct stats subfolder (split if needed)\n",
    "    destination = None\n",
    "    for pattern, subfolder in routing_map.items():\n",
    "        if pattern in parquet_file.name:\n",
    "            destination = output_base / subfolder\n",
    "            break\n",
    "\n",
    "    if destination:\n",
    "        split_or_move_parquet(parquet_file, destination)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No matching subfolder for {parquet_file.name}, skipping.\")\n",
    "\n",
    "print(\"üéâ CSV to Parquet + routing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347b58e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting max month...\n",
      "Aggregating assets to subsector-level and writing to parquet file, this may take a while...\n",
      "‚úÖ File asset_emissions_country_subsector.parquet was 13.6 MB, moved to asset_emissions/country_subsector_level/asset_emissions_country_subsector.parquet\n",
      "‚úÖ Asset parquet file exported\n"
     ]
    }
   ],
   "source": [
    "# 1. ------------ THIS NEEDS TO BE FIXED AND PROBABLY BE STORED AT ASSET LEVEL... TRY CALCULATING AT ASSET LEVEL FIRST\n",
    "# 2. CHECK OTHER TABLES FOR TEMP GRAIN (GADM & CITY)\n",
    "\n",
    "# ------------------------------------- ASSET EMISSIONS COUNTRY SUBSECTOR LEVEL -------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/asset_emissions_country_subsector.parquet\"\n",
    "output_path = \"asset_emissions/country_subsector_level\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print(\"Getting max month...\")\n",
    "max_date = con.execute(f\"\"\"\n",
    "    select max(start_time)\n",
    "    from postgres_scan('{postgres_url}', 'public', 'asset_emissions')                       \n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "print(\"Aggregating assets to subsector-level and writing to parquet file, this may take a while...\")\n",
    "con.execute(f\"\"\"\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE asset_emissions_parquet AS\n",
    "    SELECT ae.iso3_country,\n",
    "        ae.original_inventory_sector,\n",
    "        itm.activity_is_temporal,\n",
    "        ae.start_time,\n",
    "        ae.gas,\n",
    "        sch.sector,\n",
    "        ca.name as country_name,\n",
    "        ca.continent,\n",
    "        ca.unfccc_annex,\n",
    "        ca.em_finance,\n",
    "        ca.eu,\n",
    "        ca.oecd,\n",
    "        ca.developed_un,\n",
    "        ae.release,\n",
    "        sum(emissions_quantity) emissions_quantity,\n",
    "        case when activity_is_temporal = true then sum(activity) else avg(activity) end as activity,\n",
    "        sum(emissions_quantity) / sum(activity) weighted_average_emissions_factor\n",
    "    \n",
    "    FROM postgres_scan('{postgres_url}', 'public', 'asset_emissions') ae\n",
    "    LEFT JOIN postgres_scan('{postgres_url}', 'public', 'country_analysis') ca\n",
    "        ON CAST(ca.iso3_country AS VARCHAR) = CAST(ae.iso3_country AS VARCHAR)\n",
    "    LEFT JOIN (\n",
    "        SELECT DISTINCT sector, subsector FROM postgres_scan('{postgres_url}', 'public', 'asset_schema')\n",
    "    ) sch\n",
    "        ON CAST(sch.subsector AS VARCHAR) = CAST(ae.original_inventory_sector AS VARCHAR)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "        on itm.original_inventory_sector = ae.original_inventory_sector\n",
    "    \n",
    "    WHERE ae.start_time >= (\n",
    "                date_trunc('year', DATE '{max_date}') - INTERVAL '3 YEARS'\n",
    "            )\n",
    "      AND ae.gas in ('co2e_100yr','ch4')\n",
    "      AND ae.most_granular = TRUE\n",
    "    \n",
    "    GROUP BY ae.iso3_country,\n",
    "        ae.original_inventory_sector,\n",
    "        itm.activity_is_temporal,\n",
    "        ae.start_time,\n",
    "        ae.gas,\n",
    "        sch.sector,\n",
    "        ca.name,\n",
    "        ca.continent,\n",
    "        ca.unfccc_annex,\n",
    "        ca.em_finance,\n",
    "        ca.eu,\n",
    "        ca.oecd,\n",
    "        ca.developed_un,\n",
    "        ae.release;\n",
    "\n",
    "    COPY asset_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print(\"‚úÖ Asset parquet file exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a07b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Running: Getting effectiveness score for strategies\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ ERS STRATEGY SCORE ---------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/effectiveness.parquet\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Query Running: Getting effectiveness score for strategies')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TEMP TABLE rdf as\n",
    "    SELECT rdf.*\n",
    "        , coalesce(om.asset_output, 'other') asset_output\n",
    "        , cs.confidence\n",
    "        , cs.confidence_score\n",
    "        , cs.feasibility\n",
    "        , cs.feasibility_score\n",
    "        , cs.cost\n",
    "        , 6 - cs.cost_score as cost_score\n",
    "\n",
    "    FROM postgres_scan('{postgres_url}', 'public', 'reductions_data_fusion') rdf\n",
    "    LEFT JOIN read_parquet('strategy/categorical_scores/strategy_categorical_scores.parquet') cs\n",
    "        on cs.strategy_id = rdf.strategy_id \n",
    "    LEFT JOIN postgres_scan('{postgres_url}', 'public', 'asset_type_to_output_map') om\n",
    "        on om.subsector = rdf.original_inventory_sector\n",
    "        and om.asset_type = rdf.asset_type\n",
    "    \n",
    "    WHERE strategy_rank = 1\n",
    "      AND gas = 'co2e_100yr';\n",
    "\n",
    "    COPY (\n",
    "        WITH asset_rf AS (\n",
    "                SELECT\n",
    "                        asset_id\n",
    "                        , asset_output\n",
    "                        , strategy_name\n",
    "                        , strategy_description\n",
    "                        , original_inventory_sector AS subsector\n",
    "                        , old_emissions_factor\n",
    "                        , old_activity\n",
    "                        , total_emissions_reduced_per_year\n",
    "                        , (total_emissions_reduced_per_year / old_activity) AS reduction_factor\n",
    "                        , (old_emissions_factor * old_activity) AS w_inventory\n",
    "                        , confidence\n",
    "                        , confidence_score\n",
    "                        , feasibility\n",
    "                        , feasibility_score\n",
    "                        , cost\n",
    "                        , cost_score\n",
    "                \n",
    "                FROM rdf\n",
    "                \n",
    "                WHERE total_emissions_reduced_per_year IS NOT NULL\n",
    "                        AND old_activity IS NOT NULL\n",
    "                        AND old_activity > 0\n",
    "                ),\n",
    "\n",
    "        -- 1) Subsector stats using the SAME weight (activity) for mean and stdev\n",
    "        subsector_stats AS (\n",
    "                SELECT\n",
    "                        subsector\n",
    "                        , asset_output\n",
    "                        , SUM(w_inventory) AS subsector_emissions_inventory\n",
    "                       \n",
    "                        , SUM(total_emissions_reduced_per_year) / NULLIF(SUM(old_activity), 0) AS mu_rf\n",
    "                        --, avg(reduction_factor) mu_rf\n",
    "                        --, stddev_samp(reduction_factor) sigma_rf\n",
    "                        , SQRT(\n",
    "                                GREATEST(\n",
    "                                        SUM(old_activity * POWER(reduction_factor, 2)) / NULLIF(SUM(old_activity), 0)\n",
    "                                                - POWER( SUM(old_activity * reduction_factor) / NULLIF(SUM(old_activity), 0), 2 ),\n",
    "                                0\n",
    "                        )\n",
    "                        ) AS sigma_rf\n",
    "                \n",
    "                FROM asset_rf\n",
    "                \n",
    "                GROUP BY subsector\n",
    "                        , asset_output\n",
    "        ),\n",
    "\n",
    "        -- 2) Asset-level z-scores\n",
    "        asset_rf_zscore AS (\n",
    "                SELECT\n",
    "                        a.asset_id\n",
    "                        , a.asset_output\n",
    "                        , a.strategy_name\n",
    "                        , a.strategy_description\n",
    "                        , a.subsector\n",
    "                        , a.old_emissions_factor\n",
    "                        , a.old_activity\n",
    "                        , a.total_emissions_reduced_per_year\n",
    "                        , a.reduction_factor\n",
    "                        , a.w_inventory\n",
    "                        , s.mu_rf\n",
    "                        , s.sigma_rf\n",
    "                        , CASE\n",
    "                                WHEN s.sigma_rf IS NULL OR s.sigma_rf < 1e-12 THEN 0.0\n",
    "                                ELSE (a.reduction_factor - s.mu_rf) / s.sigma_rf\n",
    "                          END AS asset_rf_zscore\n",
    "                        , confidence\n",
    "                        , confidence_score\n",
    "                        , feasibility\n",
    "                        , feasibility_score\n",
    "                        , cost\n",
    "                        , cost_score\n",
    "\n",
    "                FROM asset_rf a\n",
    "                JOIN subsector_stats s \n",
    "                        on a.subsector = s.subsector\n",
    "                        and a.asset_output = s.asset_output\n",
    "\n",
    "        )\n",
    "\n",
    "         -- 3) Strategy roll-up: inventory-weighted mean of asset z\n",
    "        select strategy_name\n",
    "                , strategy_description\n",
    "                , subsector\n",
    "                , asset_count\n",
    "                , old_activity\n",
    "                , strategy_emissions_inventory\n",
    "                , total_emissions_reduced_per_year\n",
    "                , reduction_factor \n",
    "                , strategy_rf_zscore\n",
    "                , rank() over (partition by subsector order by strategy_rf_zscore desc) score_rank\n",
    "                , confidence\n",
    "                , confidence_score\n",
    "                , feasibility\n",
    "                , feasibility_score\n",
    "                , cost\n",
    "                , cost_score\n",
    "\n",
    "        from (\n",
    "                SELECT\n",
    "                        arz.strategy_name\n",
    "                        , arz.strategy_description\n",
    "                        , arz.subsector\n",
    "                        , count(distinct arz.asset_id) asset_count\n",
    "                        , sum(arz.old_activity) old_activity\n",
    "                        , sum(arz.w_inventory) strategy_emissions_inventory\n",
    "                        , sum(arz.total_emissions_reduced_per_year) total_emissions_reduced_per_year\n",
    "                        , sum(arz.total_emissions_reduced_per_year) / sum(arz.old_activity) as reduction_factor\n",
    "                        --, avg(arz.w_inventory * arz.asset_rf_zscore) / NULLIF(SUM(arz.w_inventory), 0) AS strategy_rf_zscore\n",
    "                        , avg(arz.asset_rf_zscore) strategy_rf_zscore\n",
    "                        , confidence\n",
    "                        , confidence_score\n",
    "                        , feasibility\n",
    "                        , feasibility_score\n",
    "                        , cost\n",
    "                        , cost_score\n",
    "                \n",
    "                FROM asset_rf_zscore arz\n",
    "                \n",
    "                GROUP BY arz.strategy_name\n",
    "                        , arz.strategy_description\n",
    "                        , arz.subsector\n",
    "                        , arz.confidence\n",
    "                        , arz.confidence_score\n",
    "                        , arz.feasibility\n",
    "                        , arz.feasibility_score\n",
    "                        , arz.cost\n",
    "                        , arz.cost_score\n",
    "        ) score_subsector_rank\n",
    "\n",
    "        where total_emissions_reduced_per_year > 0\n",
    "                and total_emissions_reduced_per_year is not null\n",
    "\n",
    "        order by subsector, score_rank                                       \n",
    "    \n",
    "    ) TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41388a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Running: Getting effectiveness score for assets\n"
     ]
    },
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Type with name c does not exist!\nDid you mean \"char\"?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCatalogException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m con = duckdb.connect()\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mQuery Running: Getting effectiveness score for assets\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'''\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[33;43m    INSTALL postgres;\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[33;43m    LOAD postgres;\u001b[39;49m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[33;43m    CREATE TEMP TABLE rdf as\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[33;43m    SELECT rdf.*\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[33;43m        , coalesce(om.asset_output, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mother\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m) asset_output\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[33;43m        , cs.confidence\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[33;43m        , cs.confidence_score\u001b[39;49m\n\u001b[32m     19\u001b[39m \u001b[33;43m        , cs.feasibility\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[33;43m        , cs.feasibility_score\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[33;43m        , cs.cost\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[33;43m        , 6 - cs.cost_score as cost_score\u001b[39;49m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[33;43m    FROM postgres_scan(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpostgres_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpublic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreductions_data_fusion\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m) rdf\u001b[39;49m\n\u001b[32m     25\u001b[39m \u001b[33;43m    LEFT JOIN read_parquet(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstrategy/categorical_scores/strategy_categorical_scores.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m) cs\u001b[39;49m\n\u001b[32m     26\u001b[39m \u001b[33;43m        on cs.strategy_id = rdf.strategy_id \u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[33;43m    LEFT JOIN postgres_scan(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpostgres_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpublic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43masset_type_to_output_map\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m) om\u001b[39;49m\n\u001b[32m     28\u001b[39m \u001b[33;43m        on om.subsector = rdf.original_inventory_sector\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[33;43m        and om.asset_type = rdf.asset_type\u001b[39;49m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33;43m    WHERE strategy_rank = 1\u001b[39;49m\n\u001b[32m     32\u001b[39m \u001b[33;43m      AND gas = \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mco2e_100yr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     33\u001b[39m \u001b[33;43m      and rdf.original_inventory_sector in (\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msolid-waste-disposal\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43miron-and-steel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcement\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43melectricity-generation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwater-reservoirs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, c\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mropland-fires\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m);\u001b[39;49m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[33;43m    COPY (\u001b[39;49m\n\u001b[32m     36\u001b[39m \u001b[33;43m        WITH asset_rf AS (\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[33;43m                SELECT\u001b[39;49m\n\u001b[32m     38\u001b[39m \u001b[33;43m                        asset_id\u001b[39;49m\n\u001b[32m     39\u001b[39m \u001b[33;43m                        , asset_output\u001b[39;49m\n\u001b[32m     40\u001b[39m \u001b[33;43m                        , strategy_name\u001b[39;49m\n\u001b[32m     41\u001b[39m \u001b[33;43m                        , strategy_description\u001b[39;49m\n\u001b[32m     42\u001b[39m \u001b[33;43m                        , original_inventory_sector AS subsector\u001b[39;49m\n\u001b[32m     43\u001b[39m \u001b[33;43m                        , old_emissions_factor\u001b[39;49m\n\u001b[32m     44\u001b[39m \u001b[33;43m                        , old_activity\u001b[39;49m\n\u001b[32m     45\u001b[39m \u001b[33;43m                        , total_emissions_reduced_per_year\u001b[39;49m\n\u001b[32m     46\u001b[39m \u001b[33;43m                        , (total_emissions_reduced_per_year / old_activity) AS reduction_factor\u001b[39;49m\n\u001b[32m     47\u001b[39m \u001b[33;43m                        , (old_emissions_factor * old_activity) AS w_inventory\u001b[39;49m\n\u001b[32m     48\u001b[39m \u001b[33;43m                        , confidence\u001b[39;49m\n\u001b[32m     49\u001b[39m \u001b[33;43m                        , confidence_score\u001b[39;49m\n\u001b[32m     50\u001b[39m \u001b[33;43m                        , feasibility\u001b[39;49m\n\u001b[32m     51\u001b[39m \u001b[33;43m                        , feasibility_score\u001b[39;49m\n\u001b[32m     52\u001b[39m \u001b[33;43m                        , cost\u001b[39;49m\n\u001b[32m     53\u001b[39m \u001b[33;43m                        , cost_score\u001b[39;49m\n\u001b[32m     54\u001b[39m \n\u001b[32m     55\u001b[39m \u001b[33;43m                FROM rdf\u001b[39;49m\n\u001b[32m     56\u001b[39m \n\u001b[32m     57\u001b[39m \u001b[33;43m                WHERE total_emissions_reduced_per_year IS NOT NULL\u001b[39;49m\n\u001b[32m     58\u001b[39m \u001b[33;43m                        AND old_activity IS NOT NULL\u001b[39;49m\n\u001b[32m     59\u001b[39m \u001b[33;43m                        AND old_activity > 0\u001b[39;49m\n\u001b[32m     60\u001b[39m \u001b[33;43m                ),\u001b[39;49m\n\u001b[32m     61\u001b[39m \n\u001b[32m     62\u001b[39m \u001b[33;43m        subsector_stats AS (\u001b[39;49m\n\u001b[32m     63\u001b[39m \u001b[33;43m                SELECT\u001b[39;49m\n\u001b[32m     64\u001b[39m \u001b[33;43m                        subsector\u001b[39;49m\n\u001b[32m     65\u001b[39m \u001b[33;43m                        , asset_output\u001b[39;49m\n\u001b[32m     66\u001b[39m \u001b[33;43m                        , SUM(w_inventory) AS subsector_emissions_inventory\u001b[39;49m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[33;43m                        , SUM(total_emissions_reduced_per_year) / NULLIF(SUM(old_activity), 0) AS mu_rf\u001b[39;49m\n\u001b[32m     69\u001b[39m \u001b[33;43m                        --, avg(reduction_factor) mu_rf\u001b[39;49m\n\u001b[32m     70\u001b[39m \u001b[33;43m                        --, stddev_samp(reduction_factor) sigma_rf\u001b[39;49m\n\u001b[32m     71\u001b[39m \u001b[33;43m                        , SQRT(\u001b[39;49m\n\u001b[32m     72\u001b[39m \u001b[33;43m                                GREATEST(\u001b[39;49m\n\u001b[32m     73\u001b[39m \u001b[33;43m                                        SUM(old_activity * POWER(reduction_factor, 2)) / NULLIF(SUM(old_activity), 0)\u001b[39;49m\n\u001b[32m     74\u001b[39m \u001b[33;43m                                                - POWER( SUM(old_activity * reduction_factor) / NULLIF(SUM(old_activity), 0), 2 ),\u001b[39;49m\n\u001b[32m     75\u001b[39m \u001b[33;43m                                0\u001b[39;49m\n\u001b[32m     76\u001b[39m \u001b[33;43m                        )\u001b[39;49m\n\u001b[32m     77\u001b[39m \u001b[33;43m                        ) AS sigma_rf\u001b[39;49m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[33;43m                FROM asset_rf\u001b[39;49m\n\u001b[32m     80\u001b[39m \n\u001b[32m     81\u001b[39m \u001b[33;43m                GROUP BY subsector\u001b[39;49m\n\u001b[32m     82\u001b[39m \u001b[33;43m                        , asset_output\u001b[39;49m\n\u001b[32m     83\u001b[39m \u001b[33;43m        )\u001b[39;49m\n\u001b[32m     84\u001b[39m \n\u001b[32m     85\u001b[39m \u001b[33;43m        SELECT\u001b[39;49m\n\u001b[32m     86\u001b[39m \u001b[33;43m                a.asset_id\u001b[39;49m\n\u001b[32m     87\u001b[39m \u001b[33;43m                , a.asset_output\u001b[39;49m\n\u001b[32m     88\u001b[39m \u001b[33;43m                , a.strategy_name\u001b[39;49m\n\u001b[32m     89\u001b[39m \u001b[33;43m                , a.strategy_description\u001b[39;49m\n\u001b[32m     90\u001b[39m \u001b[33;43m                , a.subsector\u001b[39;49m\n\u001b[32m     91\u001b[39m \u001b[33;43m                , a.old_emissions_factor\u001b[39;49m\n\u001b[32m     92\u001b[39m \u001b[33;43m                , a.old_activity\u001b[39;49m\n\u001b[32m     93\u001b[39m \u001b[33;43m                , a.total_emissions_reduced_per_year\u001b[39;49m\n\u001b[32m     94\u001b[39m \u001b[33;43m                , a.reduction_factor\u001b[39;49m\n\u001b[32m     95\u001b[39m \u001b[33;43m                , a.w_inventory\u001b[39;49m\n\u001b[32m     96\u001b[39m \u001b[33;43m                , s.mu_rf\u001b[39;49m\n\u001b[32m     97\u001b[39m \u001b[33;43m                , s.sigma_rf\u001b[39;49m\n\u001b[32m     98\u001b[39m \u001b[33;43m                , CASE\u001b[39;49m\n\u001b[32m     99\u001b[39m \u001b[33;43m                        WHEN s.sigma_rf IS NULL OR s.sigma_rf < 1e-12 THEN 0.0\u001b[39;49m\n\u001b[32m    100\u001b[39m \u001b[33;43m                        ELSE (a.reduction_factor - s.mu_rf) / s.sigma_rf\u001b[39;49m\n\u001b[32m    101\u001b[39m \u001b[33;43m                  END AS asset_rf_zscore\u001b[39;49m\n\u001b[32m    102\u001b[39m \n\u001b[32m    103\u001b[39m \u001b[33;43m                , CASE\u001b[39;49m\n\u001b[32m    104\u001b[39m \u001b[33;43m                        WHEN s.sigma_rf IS NULL OR s.sigma_rf < 1e-12 THEN 0.0\u001b[39;49m\n\u001b[32m    105\u001b[39m \u001b[33;43m                        ELSE (\u001b[39;49m\n\u001b[32m    106\u001b[39m \u001b[33;43m                            -- Step 1: Z-score bounded by -3 -> 3\u001b[39;49m\n\u001b[32m    107\u001b[39m \u001b[33;43m                            CASE\u001b[39;49m\n\u001b[32m    108\u001b[39m \u001b[33;43m                                WHEN (a.reduction_factor - s.mu_rf) / s.sigma_rf < -3 THEN -3\u001b[39;49m\n\u001b[32m    109\u001b[39m \u001b[33;43m                                WHEN (a.reduction_factor - s.mu_rf) / s.sigma_rf > 3 THEN 3\u001b[39;49m\n\u001b[32m    110\u001b[39m \u001b[33;43m                                ELSE (a.reduction_factor - s.mu_rf) / s.sigma_rf\u001b[39;49m\n\u001b[32m    111\u001b[39m \u001b[33;43m                            END\u001b[39;49m\n\u001b[32m    112\u001b[39m \n\u001b[32m    113\u001b[39m \u001b[33;43m                            -- Step 2: Normalize to 1‚Äì5 score\u001b[39;49m\n\u001b[32m    114\u001b[39m \u001b[33;43m                            + 3.0\u001b[39;49m\n\u001b[32m    115\u001b[39m \u001b[33;43m                        ) * (4.0 / 6.0) + 1.0\u001b[39;49m\n\u001b[32m    116\u001b[39m \u001b[33;43m                    END AS asset_rf_score\u001b[39;49m\n\u001b[32m    117\u001b[39m \n\u001b[32m    118\u001b[39m \u001b[33;43m                , confidence\u001b[39;49m\n\u001b[32m    119\u001b[39m \u001b[33;43m                , confidence_score\u001b[39;49m\n\u001b[32m    120\u001b[39m \u001b[33;43m                , feasibility\u001b[39;49m\n\u001b[32m    121\u001b[39m \u001b[33;43m                , feasibility_score\u001b[39;49m\n\u001b[32m    122\u001b[39m \u001b[33;43m                , cost\u001b[39;49m\n\u001b[32m    123\u001b[39m \u001b[33;43m                , cost_score\u001b[39;49m\n\u001b[32m    124\u001b[39m \n\u001b[32m    125\u001b[39m \u001b[33;43m        FROM asset_rf a\u001b[39;49m\n\u001b[32m    126\u001b[39m \u001b[33;43m        JOIN subsector_stats s \u001b[39;49m\n\u001b[32m    127\u001b[39m \u001b[33;43m                on a.subsector = s.subsector\u001b[39;49m\n\u001b[32m    128\u001b[39m \u001b[33;43m                and a.asset_output = s.asset_output\u001b[39;49m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \n\u001b[32m    131\u001b[39m \n\u001b[32m    132\u001b[39m \u001b[33;43m    ) TO \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparquet_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m (FORMAT PARQUET);\u001b[39;49m\n\u001b[32m    133\u001b[39m \u001b[33;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m con.close()\n",
      "\u001b[31mCatalogException\u001b[39m: Catalog Error: Type with name c does not exist!\nDid you mean \"char\"?"
     ]
    }
   ],
   "source": [
    "# -------------------------------- this is asset level scoring! ------------------------------------\n",
    "\n",
    "# ------------------------------------ ERS STRATEGY SCORE ---------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/effectiveness_asset.parquet\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Query Running: Getting effectiveness score for assets')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TEMP TABLE rdf as\n",
    "    SELECT rdf.*\n",
    "        , coalesce(om.asset_output, 'other') asset_output\n",
    "        , cs.confidence\n",
    "        , cs.confidence_score\n",
    "        , cs.feasibility\n",
    "        , cs.feasibility_score\n",
    "        , cs.cost\n",
    "        , 6 - cs.cost_score as cost_score\n",
    "\n",
    "    FROM postgres_scan('{postgres_url}', 'public', 'reductions_data_fusion') rdf\n",
    "    LEFT JOIN read_parquet('strategy/categorical_scores/strategy_categorical_scores.parquet') cs\n",
    "        on cs.strategy_id = rdf.strategy_id \n",
    "    LEFT JOIN postgres_scan('{postgres_url}', 'public', 'asset_type_to_output_map') om\n",
    "        on om.subsector = rdf.original_inventory_sector\n",
    "        and om.asset_type = rdf.asset_type\n",
    "    \n",
    "    WHERE strategy_rank = 1\n",
    "      AND gas = 'co2e_100yr'\n",
    "      and rdf.original_inventory_sector in ('solid-waste-disposal', 'iron-and-steel', 'cement', 'electricity-generation', 'water-reservoirs', 'cropland-fires');\n",
    "\n",
    "    COPY (\n",
    "        WITH asset_rf AS (\n",
    "                SELECT\n",
    "                        asset_id\n",
    "                        , asset_output\n",
    "                        , strategy_name\n",
    "                        , strategy_description\n",
    "                        , original_inventory_sector AS subsector\n",
    "                        , old_emissions_factor\n",
    "                        , old_activity\n",
    "                        , total_emissions_reduced_per_year\n",
    "                        , (total_emissions_reduced_per_year / old_activity) AS reduction_factor\n",
    "                        , (old_emissions_factor * old_activity) AS w_inventory\n",
    "                        , confidence\n",
    "                        , confidence_score\n",
    "                        , feasibility\n",
    "                        , feasibility_score\n",
    "                        , cost\n",
    "                        , cost_score\n",
    "                \n",
    "                FROM rdf\n",
    "                \n",
    "                WHERE total_emissions_reduced_per_year IS NOT NULL\n",
    "                        AND old_activity IS NOT NULL\n",
    "                        AND old_activity > 0\n",
    "                ),\n",
    "\n",
    "        subsector_stats AS (\n",
    "                SELECT\n",
    "                        subsector\n",
    "                        , asset_output\n",
    "                        , SUM(w_inventory) AS subsector_emissions_inventory\n",
    "                       \n",
    "                        , SUM(total_emissions_reduced_per_year) / NULLIF(SUM(old_activity), 0) AS mu_rf\n",
    "                        --, avg(reduction_factor) mu_rf\n",
    "                        --, stddev_samp(reduction_factor) sigma_rf\n",
    "                        , SQRT(\n",
    "                                GREATEST(\n",
    "                                        SUM(old_activity * POWER(reduction_factor, 2)) / NULLIF(SUM(old_activity), 0)\n",
    "                                                - POWER( SUM(old_activity * reduction_factor) / NULLIF(SUM(old_activity), 0), 2 ),\n",
    "                                0\n",
    "                        )\n",
    "                        ) AS sigma_rf\n",
    "                \n",
    "                FROM asset_rf\n",
    "                \n",
    "                GROUP BY subsector\n",
    "                        , asset_output\n",
    "        )\n",
    "                \n",
    "        SELECT\n",
    "                a.asset_id\n",
    "                , a.asset_output\n",
    "                , a.strategy_name\n",
    "                , a.strategy_description\n",
    "                , a.subsector\n",
    "                , a.old_emissions_factor\n",
    "                , a.old_activity\n",
    "                , a.total_emissions_reduced_per_year\n",
    "                , a.reduction_factor\n",
    "                , a.w_inventory\n",
    "                , s.mu_rf\n",
    "                , s.sigma_rf\n",
    "                , CASE\n",
    "                        WHEN s.sigma_rf IS NULL OR s.sigma_rf < 1e-12 THEN 0.0\n",
    "                        ELSE (a.reduction_factor - s.mu_rf) / s.sigma_rf\n",
    "                  END AS asset_rf_zscore\n",
    "                \n",
    "                , CASE\n",
    "                        WHEN s.sigma_rf IS NULL OR s.sigma_rf < 1e-12 THEN 0.0\n",
    "                        ELSE (\n",
    "                            -- Step 1: Z-score bounded by -3 -> 3\n",
    "                            CASE\n",
    "                                WHEN (a.reduction_factor - s.mu_rf) / s.sigma_rf < -3 THEN -3\n",
    "                                WHEN (a.reduction_factor - s.mu_rf) / s.sigma_rf > 3 THEN 3\n",
    "                                ELSE (a.reduction_factor - s.mu_rf) / s.sigma_rf\n",
    "                            END\n",
    "                            \n",
    "                            -- Step 2: Normalize to 1‚Äì5 score\n",
    "                            + 3.0\n",
    "                        ) * (4.0 / 6.0) + 1.0\n",
    "                    END AS asset_rf_score\n",
    "                \n",
    "                , confidence\n",
    "                , confidence_score\n",
    "                , feasibility\n",
    "                , feasibility_score\n",
    "                , cost\n",
    "                , cost_score\n",
    "\n",
    "        FROM asset_rf a\n",
    "        JOIN subsector_stats s \n",
    "                on a.subsector = s.subsector\n",
    "                and a.asset_output = s.asset_output\n",
    "\n",
    "                                         \n",
    "    \n",
    "    ) TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3e1cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Running: Aggregating asset data to annual level and adding ERS...\n",
      "Deleting asset-moer dataframes to free up memory.\n",
      "Original asset file deleted\n",
      "‚ö° Splitting asset_annual_emissions_moer.parquet (673.5 MB)...\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_1.parquet (46.1 MB, rows 0‚Äì426113)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_2.parquet (46.0 MB, rows 426113‚Äì852226)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_3.parquet (46.0 MB, rows 852226‚Äì1278339)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_4.parquet (46.1 MB, rows 1278339‚Äì1704452)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_5.parquet (46.2 MB, rows 1704452‚Äì2130565)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_6.parquet (46.1 MB, rows 2130565‚Äì2556678)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_7.parquet (46.1 MB, rows 2556678‚Äì2982791)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_8.parquet (46.2 MB, rows 2982791‚Äì3408904)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_9.parquet (46.1 MB, rows 3408904‚Äì3835017)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_10.parquet (46.1 MB, rows 3835017‚Äì4261130)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_11.parquet (46.2 MB, rows 4261130‚Äì4687243)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_12.parquet (46.1 MB, rows 4687243‚Äì5113356)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_13.parquet (41.5 MB, rows 5113356‚Äì5539469)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_14.parquet (17.9 MB, rows 5539469‚Äì5965582)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_15.parquet (17.8 MB, rows 5965582‚Äì6391695)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_16.parquet (17.8 MB, rows 6391695‚Äì6817808)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_17.parquet (17.8 MB, rows 6817808‚Äì7243921)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_18.parquet (18.0 MB, rows 7243921‚Äì7670034)\n",
      "  - Saved asset_emissions/asset_level_2024/asset_annual_emissions_moer_chunk_19.parquet (2.5 MB, rows 7670034‚Äì7719063)\n",
      "üóëÔ∏è Deleted original asset_annual_emissions_moer.parquet\n",
      "‚úÖ Splitting complete\n",
      "Successfully updated asset_level data.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ Asset Annual Emissions ------------------------------------\n",
    "\n",
    "################### CURRENTLY USING DATA FUSION TABLES, NEEDS TO BE CHANGED BACK WHEN READY\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/asset_annual_emissions.parquet\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Query Running: Aggregating asset data to annual level and adding ERS...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE asset_annual_emissions_parquet AS\n",
    "\tselect extract(year from ae.start_time) as year\n",
    "\t\t, cast(ae.asset_id as text) as asset_id\n",
    "\t\t, ai.asset_type\n",
    "\t\t, CASE \n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'iron-and-steel' AND ai.asset_type LIKE '%BF%' \n",
    "\t\t\t\t\tTHEN '{{''iron-and-steel'': [''BF'', ''DRI-EAF'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Refinery%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Refinery'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Smelting%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Smelting'']}}'\n",
    "\t\t\t\tELSE 'all' \n",
    "\t\t\tEND AS asset_type_2\n",
    "\t\t, ai.asset_name\n",
    "\t\t, ae.iso3_country\n",
    "\t\t, ca.name as country_name\n",
    "        , abc.region balancing_authority_region\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ae.original_inventory_sector as subsector\n",
    "        , itm.activity_is_temporal\n",
    "        , ae.lat_lon\n",
    "\t\t, al.gadm_1\n",
    "\t\t, al.gadm_2\n",
    "\t\t, al.ghs_fua\n",
    "\t\t, al.city_id\n",
    "\t\t, ae.other1\n",
    "\t\t, ae.other2\n",
    "\t\t, ae.other3\n",
    "\t\t, ae.other4\n",
    "\t\t, ae.other5\n",
    "\t\t, ae.other6\n",
    "\t\t, ae.other7\n",
    "\t\t, ae.other8\n",
    "\t\t, ae.other9\n",
    "\t\t, ae.other10\n",
    "\t\t, ae.activity_units\n",
    "\t\t, sum(capacity) capacity\n",
    "\t\t, case when activity_is_temporal = true then sum(activity) else avg(activity) end as activity\n",
    "\t\t, avg(emissions_factor) average_emissions_factor\n",
    "\t\t, sum(emissions_quantity) emissions_quantity\n",
    "        , 'asset' as reduction_q_type\n",
    "        , ers.strategy_id\n",
    "\t\t, ers.strategy_name\n",
    "\t\t, ers.strategy_description\n",
    "\t\t, ers.mechanism\n",
    "\t\t, ers.old_activity\n",
    "\t\t, ers.affected_activity\n",
    "\t\t, ers.old_emissions_factor\n",
    "\t\t, ers.new_emissions_factor\n",
    "\t\t, ers.emissions_reduced_at_asset\n",
    "\t\t, ers.induced_sector_1\n",
    "\t\t, ers.induced_sector_1_induced_emissions\n",
    "\t\t, ers.induced_sector_2\n",
    "\t\t, ers.induced_sector_2_induced_emissions\n",
    "\t\t, ers.induced_sector_3\n",
    "\t\t, ers.induced_sector_3_induced_emissions\n",
    "\t\t, ers.total_emissions_reduced_per_year\n",
    "\n",
    "\tfrom postgres_scan('{postgres_url}','public', 'asset_emissions_data_fusion') ae\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'asset_information_data_fusion') ai\n",
    "\t\ton ai.asset_id = ae.asset_id\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'asset_location_data_fusion') al\n",
    "\t\ton al.asset_id = ae.asset_id\n",
    "\tleft join (\n",
    "\t\tselect distinct sector, subsector from postgres_scan('{postgres_url}','public', 'asset_schema')\n",
    "\t) asch\n",
    "\t\ton cast(asch.subsector as varchar) = cast(ae.original_inventory_sector as varchar)\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(ae.iso3_country as varchar)\n",
    "    left join postgres_scan('{postgres_url}','public', 'asset_ba_crosswalk') abc\n",
    "\t\ton cast(abc.asset_id as text) = cast(ae.asset_id as text)\n",
    "    left join (\n",
    "\t\tselect rdf.* \n",
    "\t\tfrom postgres_scan('{postgres_url}','public','reductions_data_fusion') rdf\n",
    "        where strategy_rank = 1\n",
    "\t\t\tand rdf.gas = 'co2e_100yr'\n",
    "    ) ers\n",
    "\t\ton ers.asset_id = ae.asset_id\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "         on cast(itm.original_inventory_sector as text) = cast(ae.original_inventory_sector as text)\n",
    "\n",
    "\twhere extract(year from ae.start_time) = 2024\n",
    "\t\tand ae.most_granular = true\n",
    "\t\tand ae.gas = 'co2e_100yr'\n",
    "\n",
    "\n",
    "\tgroup by extract(year from ae.start_time)\n",
    "\t\t, ae.asset_id\n",
    "\t\t, ai.asset_type\n",
    "        , CASE \n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'iron-and-steel' AND ai.asset_type LIKE '%BF%' \n",
    "\t\t\t\t\tTHEN '{{''iron-and-steel'': [''BF'', ''DRI-EAF'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Refinery%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Refinery'']}}'\n",
    "\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Smelting%' \n",
    "\t\t\t\t\tTHEN '{{''aluminum'': [''Smelting'']}}'\n",
    "\t\t\t\tELSE 'all' \n",
    "\t\t\tEND\n",
    "\t\t, ai.asset_name\n",
    "\t\t, ae.iso3_country\n",
    "\t\t, ca.name\n",
    "        , abc.region\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ae.original_inventory_sector\n",
    "        , itm.activity_is_temporal\n",
    "        , ae.lat_lon\n",
    "\t\t, al.gadm_1\n",
    "\t\t, al.gadm_2\n",
    "\t\t, al.ghs_fua\n",
    "\t\t, al.city_id\n",
    "\t\t, ae.other1\n",
    "\t\t, ae.other2\n",
    "\t\t, ae.other3\n",
    "\t\t, ae.other4\n",
    "\t\t, ae.other5\n",
    "\t\t, ae.other6\n",
    "\t\t, ae.other7\n",
    "\t\t, ae.other8\n",
    "\t\t, ae.other9\n",
    "\t\t, ae.other10\n",
    "\t\t, ae.activity_units\n",
    "        , ers.strategy_id\n",
    "\t\t, ers.strategy_name\n",
    "\t\t, ers.strategy_description\n",
    "\t\t, ers.mechanism\n",
    "\t\t, ers.old_activity\n",
    "\t\t, ers.affected_activity\n",
    "\t\t, ers.old_emissions_factor\n",
    "\t\t, ers.new_emissions_factor\n",
    "\t\t, ers.emissions_reduced_at_asset\n",
    "\t\t, ers.induced_sector_1\n",
    "\t\t, ers.induced_sector_1_induced_emissions\n",
    "\t\t, ers.induced_sector_2\n",
    "\t\t, ers.induced_sector_2_induced_emissions\n",
    "\t\t, ers.induced_sector_3\n",
    "\t\t, ers.induced_sector_3_induced_emissions\n",
    "\t\t, ers.total_emissions_reduced_per_year\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT \n",
    "\t\t\tNULL AS year,\n",
    "\t\t\tasset_id,\n",
    "\t\t\tgr.asset_type,\n",
    "\t\t\tNULL AS asset_type_2,\n",
    "\t\t\tgr.asset_name,\n",
    "\t\t\tca.iso3_country,\n",
    "\t\t\tca.name AS country_name,\n",
    "\t\t\tNULL AS balancing_authority_region,\n",
    "\t\t\tca.continent,\n",
    "\t\t\tca.eu,\n",
    "\t\t\tca.oecd,\n",
    "\t\t\tca.unfccc_annex,\n",
    "\t\t\tca.developed_un,\n",
    "\t\t\tca.em_finance,\n",
    "\t\t\tasch.sector,\n",
    "\t\t\tgr.original_inventory_sector AS subsector,\n",
    "\t\t\titm.activity_is_temporal,\n",
    "            null as lat_lon,\n",
    "\t\t\tCASE \n",
    "\t\t\t\tWHEN gb.admin_level = 1 THEN gb.gadm_id \n",
    "\t\t\t\tWHEN gb.admin_level = 2 THEN gb.immediate_parent \n",
    "\t\t\t\tELSE NULL \n",
    "\t\t\tEND AS gadm_1,\n",
    "\t\t\tCASE \n",
    "\t\t\t\tWHEN gb.admin_level = 2 THEN gb.gadm_id \n",
    "\t\t\t\tELSE NULL \n",
    "\t\t\tEND AS gadm_2,\n",
    "\t\t\tNULL AS ghs_fua,\n",
    "\t\t\tNULL AS city_id,\n",
    "\t\t\tNULL AS other1,\n",
    "\t\t\tNULL AS other2,\n",
    "\t\t\tNULL AS other3,\n",
    "\t\t\tNULL AS other4,\n",
    "\t\t\tNULL AS other5,\n",
    "\t\t\tNULL AS other6,\n",
    "\t\t\tNULL AS other7,\n",
    "\t\t\tNULL AS other8,\n",
    "\t\t\tNULL AS other9,\n",
    "\t\t\tNULL AS other10,\n",
    "\t\t\tNULL AS activity_units,\n",
    "\t\t\t0 AS capacity,\n",
    "\t\t\t0 AS activity,\n",
    "\t\t\t0 AS average_emissions_factor,\n",
    "\t\t\t0 AS emissions_quantity,\n",
    "\t\t\t'remainder' AS reduction_q_type,\n",
    "\t\t\tgr.strategy_id,\n",
    "\t\t\tgr.strategy_name,\n",
    "\t\t\tgr.strategy_description,\n",
    "\t\t\tgr.mechanism,\n",
    "\t\t\tgr.old_activity,\n",
    "\t\t\tgr.affected_activity,\n",
    "\t\t\tgr.old_emissions_factor,\n",
    "\t\t\tgr.new_emissions_factor,\n",
    "\t\t\tgr.emissions_reduced_at_asset,\n",
    "\t\t\tgr.induced_sector_1,\n",
    "\t\t\tgr.induced_sector_1_induced_emissions,\n",
    "\t\t\tgr.induced_sector_2,\n",
    "\t\t\tgr.induced_sector_2_induced_emissions,\n",
    "\t\t\tgr.induced_sector_3,\n",
    "\t\t\tgr.induced_sector_3_induced_emissions,\n",
    "\t\t\tgr.total_emissions_reduced_per_year\n",
    "        \n",
    "        FROM postgres_scan('{postgres_url}','public', 'gadm_reductions_data_fusion') gr\n",
    "        LEFT JOIN (\n",
    "\t\t\tselect distinct sector, subsector from postgres_scan('{postgres_url}','public', 'asset_schema')\n",
    "\t\t) asch\n",
    "\t\t\ton cast(asch.subsector as varchar) = cast(gr.original_inventory_sector as varchar)\n",
    "        LEFT JOIN (\n",
    "\t\t\tselect distinct gadm_id, iso3_country, admin_level, immediate_parent\n",
    "            from postgres_scan('{postgres_url}','public', 'gadm_boundaries')\n",
    "        ) gb\n",
    "\t\t\ton gb.gadm_id = gr.asset_id\n",
    "        LEFT JOIN postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\t\ton ca.iso3_country = gb.iso3_country\n",
    "        LEFT JOIN postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "        \ton cast(itm.original_inventory_sector as text) = cast(gr.original_inventory_sector as text)\n",
    "            \n",
    "        WHERE gr.strategy_rank = 1\n",
    "\t\t\tand gr.gas = 'co2e_100yr'\n",
    "        ;\n",
    "            \n",
    "    COPY asset_annual_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "\n",
    "# removing forestry sectors from query\n",
    "\t\t# and ae.original_inventory_sector not in ('forest-land-clearing',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'forest-land-degradation',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'forest-land-fires',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'net-forest-land',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'net-shrubgrass',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'net-wetland',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'removals',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'shrubgrass-fires',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'water-reservoirs',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'wetland-fires')\n",
    "\n",
    "con.close()\n",
    "\n",
    "## ---------------------------------- ADD MOER FACTORS --------------------------------------\n",
    "parquet_path = Path('zzz_landing_zone/asset_annual_emissions.parquet')\n",
    "landing_zone_path = Path('zzz_landing_zone/asset_annual_emissions_moer.parquet')\n",
    "output_path =  Path('asset_emissions/asset_level_2024')\n",
    "\n",
    "df_asset = pd.read_parquet(parquet_path)\n",
    "\n",
    "# adding moer data to assets\n",
    "asset_moer_df = data_add_moer(df_asset, cond={\"moer\": True})\n",
    "\n",
    "# converting data to new parquet file\n",
    "asset_moer_df.to_parquet(landing_zone_path, index=False)\n",
    "\n",
    "# freeing up memory\n",
    "print(\"Deleting asset-moer dataframes to free up memory.\")\n",
    "del df_asset\n",
    "del asset_moer_df\n",
    "gc.collect()\n",
    "\n",
    "# deleting original asset file\n",
    "parquet_path.unlink()\n",
    "print(\"Original asset file deleted\")\n",
    "\n",
    "# splitting asset data into chunks\n",
    "split_or_move_parquet(landing_zone_path, output_path)\n",
    "\n",
    "print(\"Successfully updated asset_level data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c799bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------- Uncomment and run this if you created the file in the block above, but couldn't get it to split and moved to the correct folder\n",
    "\n",
    "# parquet_path = Path('zzz_landing_zone/asset_annual_emissions.parquet')\n",
    "# landing_zone_path = Path('zzz_landing_zone/asset_annual_emissions_moer.parquet')\n",
    "# output_path =  Path('asset_emissions/asset_level_2024')\n",
    "\n",
    "# df_asset = pd.read_parquet(parquet_path)\n",
    "\n",
    "# # adding moer data to assets\n",
    "# asset_moer_df = data_add_moer(df_asset, cond={\"moer\": True})\n",
    "\n",
    "# # converting data to new parquet file\n",
    "# asset_moer_df.to_parquet(landing_zone_path, index=False)\n",
    "\n",
    "# # freeing up memory\n",
    "# print(\"Deleting asset-moer dataframes to free up memory.\")\n",
    "# del df_asset\n",
    "# del asset_moer_df\n",
    "# gc.collect()\n",
    "\n",
    "# # deleting original asset file\n",
    "# parquet_path.unlink()\n",
    "# print(\"Original asset file deleted\")\n",
    "\n",
    "# # splitting asset data into chunks\n",
    "# split_or_move_parquet(landing_zone_path, output_path)\n",
    "\n",
    "# print(\"Successfully updated asset_level data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c5914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query\n",
      "‚úÖ File gadm_0_emissions.parquet was 0.5 MB, moved to gadm_emissions/gadm_0/gadm_0_emissions.parquet\n",
      "Successfully refreshed GADM_0 data.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ GADM_0 Emissions ------------------------------------\n",
    "\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/gadm_0_emissions.parquet\"\n",
    "output_path = \"gadm_emissions/gadm_0\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print('Running query')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE gadm_0_emissions_parquet AS\n",
    "    select extract(year from g0e.start_time) as year \n",
    "        , g0e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g0e.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , gb.name gadm_0_name\n",
    "        , gb.corrected_name gadm_0_corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , g0e.original_inventory_sector subsector\n",
    "        , itm.activity_is_temporal\n",
    "        , g0e.gas\n",
    "        , case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from postgres_scan('{postgres_url}', 'public', 'gadm_0_emissions') g0e\n",
    "    left join (\n",
    "        select distinct gadm_id\n",
    "            , gid\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from postgres_scan('{postgres_url}','public', 'gadm_boundaries') \n",
    "        where admin_level = 0\n",
    "    ) as gb\n",
    "        on g0e.gadm_id = gb.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from postgres_scan('{postgres_url}','public', 'asset_schema') \n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(g0e.original_inventory_sector as varchar)\n",
    "    left join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(g0e.iso3_country as varchar)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "         on itm.original_inventory_sector = g0e.original_inventory_sector\n",
    "\n",
    "    where g0e.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "        \n",
    "    group by extract(year from g0e.start_time) \n",
    "        , g0e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g0e.iso3_country\n",
    "        , ca.name\n",
    "        , gb.name \n",
    "        , gb.corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , g0e.original_inventory_sector\n",
    "        , itm.activity_is_temporal\n",
    "        , g0e.gas;\n",
    "\n",
    "    COPY gadm_0_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "\n",
    "# and g0e.original_inventory_sector not in ('forest-land-clearing',\n",
    "#                                                 'forest-land-degradation',\n",
    "#                                                 'forest-land-fires',\n",
    "#                                                 'net-forest-land',\n",
    "#                                                 'net-shrubgrass',\n",
    "#                                                 'net-wetland',\n",
    "#                                                 'removals',\n",
    "#                                                 'shrubgrass-fires',\n",
    "#                                                 'water-reservoirs',\n",
    "#                                                 'wetland-fires')\n",
    "\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed GADM_0 data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8defd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query\n",
      "‚úÖ File gadm_1_emissions.parquet was 7.7 MB, moved to gadm_emissions/gadm_1/gadm_1_emissions.parquet\n",
      "Successfully refreshed GADM_1 data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------ GADM 1 Emissions ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/gadm_1_emissions.parquet\"\n",
    "output_path = \"gadm_emissions/gadm_1\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print('Running query')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE gadm_1_emissions_parquet AS\n",
    "    select extract(year from g1e.start_time) as year \n",
    "        , g1e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g1e.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , gb.name gadm_1_name\n",
    "        , gb.corrected_name gadm_1_corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , g1e.original_inventory_sector subsector\n",
    "        , itm.activity_is_temporal\n",
    "        , g1e.gas\n",
    "        , case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from postgres_scan('{postgres_url}', 'public', 'gadm_1_emissions') g1e\n",
    "    left join (\n",
    "        select distinct gadm_id\n",
    "            , gid\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from postgres_scan('{postgres_url}','public', 'gadm_boundaries') \n",
    "        where admin_level = 1\n",
    "    ) as gb\n",
    "        on g1e.gadm_id = gb.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from postgres_scan('{postgres_url}','public', 'asset_schema') \n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(g1e.original_inventory_sector as varchar)\n",
    "    left join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(g1e.iso3_country as varchar)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "         on itm.original_inventory_sector = g1e.original_inventory_sector\n",
    "\n",
    "    where g1e.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "        \n",
    "\n",
    "    group by extract(year from g1e.start_time) \n",
    "        , g1e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g1e.iso3_country\n",
    "        , ca.name\n",
    "        , gb.name \n",
    "        , gb.corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , g1e.original_inventory_sector\n",
    "        , itm.activity_is_temporal\n",
    "        , g1e.gas;\n",
    "\n",
    "    COPY gadm_1_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "\n",
    "# and g1e.original_inventory_sector not in ('forest-land-clearing',\n",
    "#                                                 'forest-land-degradation',\n",
    "#                                                 'forest-land-fires',\n",
    "#                                                 'net-forest-land',\n",
    "#                                                 'net-shrubgrass',\n",
    "#                                                 'net-wetland',\n",
    "#                                                 'removals',\n",
    "#                                                 'shrubgrass-fires',\n",
    "#                                                 'water-reservoirs',\n",
    "#                                                 'wetland-fires')\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed GADM_1 data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04194ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing gadm_2 query...\n",
      "Processed batch 1 (10000 rows), total rows: 10000\n",
      "Processed batch 2 (10000 rows), total rows: 20000\n",
      "Processed batch 3 (10000 rows), total rows: 30000\n",
      "Processed batch 4 (10000 rows), total rows: 40000\n",
      "Processed batch 5 (10000 rows), total rows: 50000\n",
      "Processed batch 6 (10000 rows), total rows: 60000\n",
      "Processed batch 7 (10000 rows), total rows: 70000\n",
      "Processed batch 8 (10000 rows), total rows: 80000\n",
      "Processed batch 9 (10000 rows), total rows: 90000\n",
      "Processed batch 10 (10000 rows), total rows: 100000\n",
      "Processed batch 11 (10000 rows), total rows: 110000\n",
      "Processed batch 12 (10000 rows), total rows: 120000\n",
      "Processed batch 13 (10000 rows), total rows: 130000\n",
      "Processed batch 14 (10000 rows), total rows: 140000\n",
      "Processed batch 15 (10000 rows), total rows: 150000\n",
      "Processed batch 16 (10000 rows), total rows: 160000\n",
      "Processed batch 17 (10000 rows), total rows: 170000\n",
      "Processed batch 18 (10000 rows), total rows: 180000\n",
      "Processed batch 19 (10000 rows), total rows: 190000\n",
      "Processed batch 20 (10000 rows), total rows: 200000\n",
      "Processed batch 21 (10000 rows), total rows: 210000\n",
      "Processed batch 22 (10000 rows), total rows: 220000\n",
      "Processed batch 23 (10000 rows), total rows: 230000\n",
      "Processed batch 24 (10000 rows), total rows: 240000\n",
      "Processed batch 25 (10000 rows), total rows: 250000\n",
      "Processed batch 26 (10000 rows), total rows: 260000\n",
      "Processed batch 27 (10000 rows), total rows: 270000\n",
      "Processed batch 28 (10000 rows), total rows: 280000\n",
      "Processed batch 29 (10000 rows), total rows: 290000\n",
      "Processed batch 30 (10000 rows), total rows: 300000\n",
      "Processed batch 31 (10000 rows), total rows: 310000\n",
      "Processed batch 32 (10000 rows), total rows: 320000\n",
      "Processed batch 33 (10000 rows), total rows: 330000\n",
      "Processed batch 34 (10000 rows), total rows: 340000\n",
      "Processed batch 35 (10000 rows), total rows: 350000\n",
      "Processed batch 36 (10000 rows), total rows: 360000\n",
      "Processed batch 37 (10000 rows), total rows: 370000\n",
      "Processed batch 38 (10000 rows), total rows: 380000\n",
      "Processed batch 39 (10000 rows), total rows: 390000\n",
      "Processed batch 40 (10000 rows), total rows: 400000\n",
      "Processed batch 41 (10000 rows), total rows: 410000\n",
      "Processed batch 42 (10000 rows), total rows: 420000\n",
      "Processed batch 43 (10000 rows), total rows: 430000\n",
      "Processed batch 44 (10000 rows), total rows: 440000\n",
      "Processed batch 45 (10000 rows), total rows: 450000\n",
      "Processed batch 46 (10000 rows), total rows: 460000\n",
      "Processed batch 47 (10000 rows), total rows: 470000\n",
      "Processed batch 48 (10000 rows), total rows: 480000\n",
      "Processed batch 49 (10000 rows), total rows: 490000\n",
      "Processed batch 50 (10000 rows), total rows: 500000\n",
      "Processed batch 51 (10000 rows), total rows: 510000\n",
      "Processed batch 52 (10000 rows), total rows: 520000\n",
      "Processed batch 53 (10000 rows), total rows: 530000\n",
      "Processed batch 54 (10000 rows), total rows: 540000\n",
      "Processed batch 55 (10000 rows), total rows: 550000\n",
      "Processed batch 56 (10000 rows), total rows: 560000\n",
      "Processed batch 57 (10000 rows), total rows: 570000\n",
      "Processed batch 58 (10000 rows), total rows: 580000\n",
      "Processed batch 59 (10000 rows), total rows: 590000\n",
      "Processed batch 60 (10000 rows), total rows: 600000\n",
      "Processed batch 61 (10000 rows), total rows: 610000\n",
      "Processed batch 62 (10000 rows), total rows: 620000\n",
      "Processed batch 63 (10000 rows), total rows: 630000\n",
      "Processed batch 64 (10000 rows), total rows: 640000\n",
      "Processed batch 65 (10000 rows), total rows: 650000\n",
      "Processed batch 66 (10000 rows), total rows: 660000\n",
      "Processed batch 67 (10000 rows), total rows: 670000\n",
      "Processed batch 68 (10000 rows), total rows: 680000\n",
      "Processed batch 69 (10000 rows), total rows: 690000\n",
      "Processed batch 70 (10000 rows), total rows: 700000\n",
      "Processed batch 71 (10000 rows), total rows: 710000\n",
      "Processed batch 72 (10000 rows), total rows: 720000\n",
      "Processed batch 73 (10000 rows), total rows: 730000\n",
      "Processed batch 74 (10000 rows), total rows: 740000\n",
      "Processed batch 75 (10000 rows), total rows: 750000\n",
      "Processed batch 76 (10000 rows), total rows: 760000\n",
      "Processed batch 77 (10000 rows), total rows: 770000\n",
      "Processed batch 78 (10000 rows), total rows: 780000\n",
      "Processed batch 79 (10000 rows), total rows: 790000\n",
      "Processed batch 80 (10000 rows), total rows: 800000\n",
      "Processed batch 81 (10000 rows), total rows: 810000\n",
      "Processed batch 82 (10000 rows), total rows: 820000\n",
      "Processed batch 83 (10000 rows), total rows: 830000\n",
      "Processed batch 84 (10000 rows), total rows: 840000\n",
      "Processed batch 85 (10000 rows), total rows: 850000\n",
      "Processed batch 86 (10000 rows), total rows: 860000\n",
      "Processed batch 87 (10000 rows), total rows: 870000\n",
      "Processed batch 88 (10000 rows), total rows: 880000\n",
      "Processed batch 89 (10000 rows), total rows: 890000\n",
      "Processed batch 90 (10000 rows), total rows: 900000\n",
      "Processed batch 91 (10000 rows), total rows: 910000\n",
      "Processed batch 92 (10000 rows), total rows: 920000\n",
      "Processed batch 93 (10000 rows), total rows: 930000\n",
      "Processed batch 94 (10000 rows), total rows: 940000\n",
      "Processed batch 95 (10000 rows), total rows: 950000\n",
      "Processed batch 96 (10000 rows), total rows: 960000\n",
      "Processed batch 97 (10000 rows), total rows: 970000\n",
      "Processed batch 98 (10000 rows), total rows: 980000\n",
      "Processed batch 99 (10000 rows), total rows: 990000\n",
      "Processed batch 100 (10000 rows), total rows: 1000000\n",
      "Processed batch 101 (10000 rows), total rows: 1010000\n",
      "Processed batch 102 (10000 rows), total rows: 1020000\n",
      "Processed batch 103 (10000 rows), total rows: 1030000\n",
      "Processed batch 104 (10000 rows), total rows: 1040000\n",
      "Processed batch 105 (10000 rows), total rows: 1050000\n",
      "Processed batch 106 (10000 rows), total rows: 1060000\n",
      "Processed batch 107 (10000 rows), total rows: 1070000\n",
      "Processed batch 108 (10000 rows), total rows: 1080000\n",
      "Processed batch 109 (10000 rows), total rows: 1090000\n",
      "Processed batch 110 (10000 rows), total rows: 1100000\n",
      "Processed batch 111 (10000 rows), total rows: 1110000\n",
      "Processed batch 112 (10000 rows), total rows: 1120000\n",
      "Processed batch 113 (10000 rows), total rows: 1130000\n",
      "Processed batch 114 (10000 rows), total rows: 1140000\n",
      "Processed batch 115 (10000 rows), total rows: 1150000\n",
      "Processed batch 116 (10000 rows), total rows: 1160000\n",
      "Processed batch 117 (10000 rows), total rows: 1170000\n",
      "Processed batch 118 (10000 rows), total rows: 1180000\n",
      "Processed batch 119 (10000 rows), total rows: 1190000\n",
      "Processed batch 120 (10000 rows), total rows: 1200000\n",
      "Processed batch 121 (10000 rows), total rows: 1210000\n",
      "Processed batch 122 (10000 rows), total rows: 1220000\n",
      "Processed batch 123 (10000 rows), total rows: 1230000\n",
      "Processed batch 124 (10000 rows), total rows: 1240000\n",
      "Processed batch 125 (10000 rows), total rows: 1250000\n",
      "Processed batch 126 (10000 rows), total rows: 1260000\n",
      "Processed batch 127 (10000 rows), total rows: 1270000\n",
      "Processed batch 128 (10000 rows), total rows: 1280000\n",
      "Processed batch 129 (10000 rows), total rows: 1290000\n",
      "Processed batch 130 (10000 rows), total rows: 1300000\n",
      "Processed batch 131 (10000 rows), total rows: 1310000\n",
      "Processed batch 132 (10000 rows), total rows: 1320000\n",
      "Processed batch 133 (10000 rows), total rows: 1330000\n",
      "Processed batch 134 (10000 rows), total rows: 1340000\n",
      "Processed batch 135 (10000 rows), total rows: 1350000\n",
      "Processed batch 136 (10000 rows), total rows: 1360000\n",
      "Processed batch 137 (10000 rows), total rows: 1370000\n",
      "Processed batch 138 (10000 rows), total rows: 1380000\n",
      "Processed batch 139 (10000 rows), total rows: 1390000\n",
      "Processed batch 140 (10000 rows), total rows: 1400000\n",
      "Processed batch 141 (10000 rows), total rows: 1410000\n",
      "Processed batch 142 (10000 rows), total rows: 1420000\n",
      "Processed batch 143 (10000 rows), total rows: 1430000\n",
      "Processed batch 144 (10000 rows), total rows: 1440000\n",
      "Processed batch 145 (10000 rows), total rows: 1450000\n",
      "Processed batch 146 (10000 rows), total rows: 1460000\n",
      "Processed batch 147 (10000 rows), total rows: 1470000\n",
      "Processed batch 148 (10000 rows), total rows: 1480000\n",
      "Processed batch 149 (10000 rows), total rows: 1490000\n",
      "Processed batch 150 (10000 rows), total rows: 1500000\n",
      "Processed batch 151 (10000 rows), total rows: 1510000\n",
      "Processed batch 152 (10000 rows), total rows: 1520000\n",
      "Processed batch 153 (10000 rows), total rows: 1530000\n",
      "Processed batch 154 (10000 rows), total rows: 1540000\n",
      "Processed batch 155 (10000 rows), total rows: 1550000\n",
      "Processed batch 156 (10000 rows), total rows: 1560000\n",
      "Processed batch 157 (10000 rows), total rows: 1570000\n",
      "Processed batch 158 (10000 rows), total rows: 1580000\n",
      "Processed batch 159 (10000 rows), total rows: 1590000\n",
      "Processed batch 160 (10000 rows), total rows: 1600000\n",
      "Processed batch 161 (10000 rows), total rows: 1610000\n",
      "Processed batch 162 (10000 rows), total rows: 1620000\n",
      "Processed batch 163 (10000 rows), total rows: 1630000\n",
      "Processed batch 164 (10000 rows), total rows: 1640000\n",
      "Processed batch 165 (10000 rows), total rows: 1650000\n",
      "Processed batch 166 (10000 rows), total rows: 1660000\n",
      "Processed batch 167 (10000 rows), total rows: 1670000\n",
      "Processed batch 168 (10000 rows), total rows: 1680000\n",
      "Processed batch 169 (10000 rows), total rows: 1690000\n",
      "Processed batch 170 (10000 rows), total rows: 1700000\n",
      "Processed batch 171 (10000 rows), total rows: 1710000\n",
      "Processed batch 172 (10000 rows), total rows: 1720000\n",
      "Processed batch 173 (10000 rows), total rows: 1730000\n",
      "Processed batch 174 (10000 rows), total rows: 1740000\n",
      "Processed batch 175 (10000 rows), total rows: 1750000\n",
      "Processed batch 176 (10000 rows), total rows: 1760000\n",
      "Processed batch 177 (10000 rows), total rows: 1770000\n",
      "Processed batch 178 (10000 rows), total rows: 1780000\n",
      "Processed batch 179 (10000 rows), total rows: 1790000\n",
      "Processed batch 180 (10000 rows), total rows: 1800000\n",
      "Processed batch 181 (10000 rows), total rows: 1810000\n",
      "Processed batch 182 (10000 rows), total rows: 1820000\n",
      "Processed batch 183 (10000 rows), total rows: 1830000\n",
      "Processed batch 184 (10000 rows), total rows: 1840000\n",
      "Processed batch 185 (10000 rows), total rows: 1850000\n",
      "Processed batch 186 (10000 rows), total rows: 1860000\n",
      "Processed batch 187 (10000 rows), total rows: 1870000\n",
      "Processed batch 188 (10000 rows), total rows: 1880000\n",
      "Processed batch 189 (10000 rows), total rows: 1890000\n",
      "Processed batch 190 (10000 rows), total rows: 1900000\n",
      "Processed batch 191 (10000 rows), total rows: 1910000\n",
      "Processed batch 192 (10000 rows), total rows: 1920000\n",
      "Processed batch 193 (10000 rows), total rows: 1930000\n",
      "Processed batch 194 (10000 rows), total rows: 1940000\n",
      "Processed batch 195 (10000 rows), total rows: 1950000\n",
      "Processed batch 196 (10000 rows), total rows: 1960000\n",
      "Processed batch 197 (10000 rows), total rows: 1970000\n",
      "Processed batch 198 (10000 rows), total rows: 1980000\n",
      "Processed batch 199 (10000 rows), total rows: 1990000\n",
      "Processed batch 200 (10000 rows), total rows: 2000000\n",
      "Processed batch 201 (10000 rows), total rows: 2010000\n",
      "Processed batch 202 (10000 rows), total rows: 2020000\n",
      "Processed batch 203 (10000 rows), total rows: 2030000\n",
      "Processed batch 204 (10000 rows), total rows: 2040000\n",
      "Processed batch 205 (10000 rows), total rows: 2050000\n",
      "Processed batch 206 (10000 rows), total rows: 2060000\n",
      "Processed batch 207 (10000 rows), total rows: 2070000\n",
      "Processed batch 208 (10000 rows), total rows: 2080000\n",
      "Processed batch 209 (10000 rows), total rows: 2090000\n",
      "Processed batch 210 (10000 rows), total rows: 2100000\n",
      "Processed batch 211 (10000 rows), total rows: 2110000\n",
      "Processed batch 212 (10000 rows), total rows: 2120000\n",
      "Processed batch 213 (10000 rows), total rows: 2130000\n",
      "Processed batch 214 (10000 rows), total rows: 2140000\n",
      "Processed batch 215 (10000 rows), total rows: 2150000\n",
      "Processed batch 216 (10000 rows), total rows: 2160000\n",
      "Processed batch 217 (10000 rows), total rows: 2170000\n",
      "Processed batch 218 (10000 rows), total rows: 2180000\n",
      "Processed batch 219 (10000 rows), total rows: 2190000\n",
      "Processed batch 220 (10000 rows), total rows: 2200000\n",
      "Processed batch 221 (10000 rows), total rows: 2210000\n",
      "Processed batch 222 (10000 rows), total rows: 2220000\n",
      "Processed batch 223 (10000 rows), total rows: 2230000\n",
      "Processed batch 224 (10000 rows), total rows: 2240000\n",
      "Processed batch 225 (10000 rows), total rows: 2250000\n",
      "Processed batch 226 (10000 rows), total rows: 2260000\n",
      "Processed batch 227 (10000 rows), total rows: 2270000\n",
      "Processed batch 228 (10000 rows), total rows: 2280000\n",
      "Processed batch 229 (10000 rows), total rows: 2290000\n",
      "Processed batch 230 (10000 rows), total rows: 2300000\n",
      "Processed batch 231 (10000 rows), total rows: 2310000\n",
      "Processed batch 232 (10000 rows), total rows: 2320000\n",
      "Processed batch 233 (10000 rows), total rows: 2330000\n",
      "Processed batch 234 (10000 rows), total rows: 2340000\n",
      "Processed batch 235 (10000 rows), total rows: 2350000\n",
      "Processed batch 236 (10000 rows), total rows: 2360000\n",
      "Processed batch 237 (10000 rows), total rows: 2370000\n",
      "Processed batch 238 (10000 rows), total rows: 2380000\n",
      "Processed batch 239 (10000 rows), total rows: 2390000\n",
      "Processed batch 240 (10000 rows), total rows: 2400000\n",
      "Processed batch 241 (10000 rows), total rows: 2410000\n",
      "Processed batch 242 (10000 rows), total rows: 2420000\n",
      "Processed batch 243 (10000 rows), total rows: 2430000\n",
      "Processed batch 244 (10000 rows), total rows: 2440000\n",
      "Processed batch 245 (10000 rows), total rows: 2450000\n",
      "Processed batch 246 (10000 rows), total rows: 2460000\n",
      "Processed batch 247 (10000 rows), total rows: 2470000\n",
      "Processed batch 248 (10000 rows), total rows: 2480000\n",
      "Processed batch 249 (10000 rows), total rows: 2490000\n",
      "Processed batch 250 (10000 rows), total rows: 2500000\n",
      "Processed batch 251 (10000 rows), total rows: 2510000\n",
      "Processed batch 252 (10000 rows), total rows: 2520000\n",
      "Processed batch 253 (10000 rows), total rows: 2530000\n",
      "Processed batch 254 (10000 rows), total rows: 2540000\n",
      "Processed batch 255 (10000 rows), total rows: 2550000\n",
      "Processed batch 256 (10000 rows), total rows: 2560000\n",
      "Processed batch 257 (10000 rows), total rows: 2570000\n",
      "Processed batch 258 (10000 rows), total rows: 2580000\n",
      "Processed batch 259 (10000 rows), total rows: 2590000\n",
      "Processed batch 260 (10000 rows), total rows: 2600000\n",
      "Processed batch 261 (10000 rows), total rows: 2610000\n",
      "Processed batch 262 (10000 rows), total rows: 2620000\n",
      "Processed batch 263 (10000 rows), total rows: 2630000\n",
      "Processed batch 264 (10000 rows), total rows: 2640000\n",
      "Processed batch 265 (10000 rows), total rows: 2650000\n",
      "Processed batch 266 (10000 rows), total rows: 2660000\n",
      "Processed batch 267 (10000 rows), total rows: 2670000\n",
      "Processed batch 268 (10000 rows), total rows: 2680000\n",
      "Processed batch 269 (10000 rows), total rows: 2690000\n",
      "Processed batch 270 (10000 rows), total rows: 2700000\n",
      "Processed batch 271 (10000 rows), total rows: 2710000\n",
      "Processed batch 272 (10000 rows), total rows: 2720000\n",
      "Processed batch 273 (10000 rows), total rows: 2730000\n",
      "Processed batch 274 (10000 rows), total rows: 2740000\n",
      "Processed batch 275 (10000 rows), total rows: 2750000\n",
      "Processed batch 276 (10000 rows), total rows: 2760000\n",
      "Processed batch 277 (10000 rows), total rows: 2770000\n",
      "Processed batch 278 (10000 rows), total rows: 2780000\n",
      "Processed batch 279 (10000 rows), total rows: 2790000\n",
      "Processed batch 280 (10000 rows), total rows: 2800000\n",
      "Processed batch 281 (10000 rows), total rows: 2810000\n",
      "Processed batch 282 (10000 rows), total rows: 2820000\n",
      "Processed batch 283 (10000 rows), total rows: 2830000\n",
      "Processed batch 284 (10000 rows), total rows: 2840000\n",
      "Processed batch 285 (10000 rows), total rows: 2850000\n",
      "Processed batch 286 (10000 rows), total rows: 2860000\n",
      "Processed batch 287 (10000 rows), total rows: 2870000\n",
      "Processed batch 288 (10000 rows), total rows: 2880000\n",
      "Processed batch 289 (10000 rows), total rows: 2890000\n",
      "Processed batch 290 (10000 rows), total rows: 2900000\n",
      "Processed batch 291 (10000 rows), total rows: 2910000\n",
      "Processed batch 292 (10000 rows), total rows: 2920000\n",
      "Processed batch 293 (10000 rows), total rows: 2930000\n",
      "Processed batch 294 (10000 rows), total rows: 2940000\n",
      "Processed batch 295 (10000 rows), total rows: 2950000\n",
      "Processed batch 296 (10000 rows), total rows: 2960000\n",
      "Processed batch 297 (10000 rows), total rows: 2970000\n",
      "Processed batch 298 (10000 rows), total rows: 2980000\n",
      "Processed batch 299 (10000 rows), total rows: 2990000\n",
      "Processed batch 300 (10000 rows), total rows: 3000000\n",
      "Processed batch 301 (10000 rows), total rows: 3010000\n",
      "Processed batch 302 (10000 rows), total rows: 3020000\n",
      "Processed batch 303 (10000 rows), total rows: 3030000\n",
      "Processed batch 304 (10000 rows), total rows: 3040000\n",
      "Processed batch 305 (10000 rows), total rows: 3050000\n",
      "Processed batch 306 (10000 rows), total rows: 3060000\n",
      "Processed batch 307 (10000 rows), total rows: 3070000\n",
      "Processed batch 308 (10000 rows), total rows: 3080000\n",
      "Processed batch 309 (10000 rows), total rows: 3090000\n",
      "Processed batch 310 (10000 rows), total rows: 3100000\n",
      "Processed batch 311 (10000 rows), total rows: 3110000\n",
      "Processed batch 312 (10000 rows), total rows: 3120000\n",
      "Processed batch 313 (10000 rows), total rows: 3130000\n",
      "Processed batch 314 (10000 rows), total rows: 3140000\n",
      "Processed batch 315 (10000 rows), total rows: 3150000\n",
      "Processed batch 316 (10000 rows), total rows: 3160000\n",
      "Processed batch 317 (10000 rows), total rows: 3170000\n",
      "Processed batch 318 (10000 rows), total rows: 3180000\n",
      "Processed batch 319 (10000 rows), total rows: 3190000\n",
      "Processed batch 320 (10000 rows), total rows: 3200000\n",
      "Processed batch 321 (10000 rows), total rows: 3210000\n",
      "Processed batch 322 (756 rows), total rows: 3210756\n",
      "‚ö° Splitting gadm_2_emissions.parquet (68.7 MB)...\n",
      "  - Saved gadm_emissions/gadm_2/gadm_2_emissions_chunk_1.parquet (46.4 MB, rows 0‚Äì2379854)\n",
      "  - Saved gadm_emissions/gadm_2/gadm_2_emissions_chunk_2.parquet (16.3 MB, rows 2379854‚Äì3210756)\n",
      "üóëÔ∏è Deleted original gadm_2_emissions.parquet\n",
      "‚úÖ Splitting complete\n",
      "Successfully refreshed GADM_2 data.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------- GADM 2 BATCH -----------------------------------------------------------------\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=database,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port\n",
    ")\n",
    "\n",
    "cur = conn.cursor(name='parquet_cursor')  # server-side cursor\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "     select extract(year from ge.start_time) as year \n",
    "        , gb1.gadm_id gadm_1_id\n",
    "        , gb1.name gadm_1_name\n",
    "        , gb1.corrected_name gadm_1_corrected_name\n",
    "        , ge.gadm_id gadm_2_id\n",
    "        , gb2.name gadm_2_name\n",
    "        , gb2.corrected_name gadm_2_corrected_name\n",
    "        , gb2.gid\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector subsector\n",
    "        , itm.activity_is_temporal\n",
    "        , case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from gadm_emissions ge\n",
    "    inner join (\n",
    "        select distinct gadm_id\n",
    "            , gid\n",
    "            , immediate_parent\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from gadm_boundaries\n",
    "        where admin_level = 2\n",
    "    ) as gb2\n",
    "        on ge.gadm_id = gb2.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from asset_schema\n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(ge.original_inventory_sector as varchar)\n",
    "    left join (\n",
    "        select gadm_id\n",
    "            , name\n",
    "            , corrected_name\n",
    "        from gadm_boundaries\n",
    "        where admin_level = 1\n",
    "    ) gb1\n",
    "        on gb1.gadm_id = gb2.immediate_parent\n",
    "    left join country_analysis ca\n",
    "        on cast(ca.iso3_country as varchar) = cast(ge.iso3_country as varchar)\n",
    "    left join is_temporal_map itm\n",
    "        on itm.original_inventory_sector = cast(ge.original_inventory_sector as text)\n",
    "\n",
    "    where ge.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "\n",
    "\n",
    "    group by extract(year from ge.start_time)\n",
    "        , gb1.gadm_id \n",
    "        , gb1.name\n",
    "        , gb1.corrected_name\n",
    "        , ge.gadm_id \n",
    "        , gb2.name\n",
    "        , gb2.corrected_name\n",
    "        , gb2.gid\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector\n",
    "        , itm.activity_is_temporal\n",
    "    \"\"\")\n",
    "\n",
    "        # and ge.original_inventory_sector not in ('forest-land-clearing',\n",
    "        #                                         'forest-land-degradation',\n",
    "        #                                         'forest-land-fires',\n",
    "        #                                         'net-forest-land',\n",
    "        #                                         'net-shrubgrass',\n",
    "        #                                         'net-wetland',\n",
    "        #                                         'removals',\n",
    "        #                                         'shrubgrass-fires',\n",
    "        #                                         'water-reservoirs',\n",
    "        #                                         'wetland-fires')\n",
    "\n",
    "# Set up Parquet writer\n",
    "batch_size = 10000\n",
    "output_file = \"zzz_landing_zone/gadm_2_emissions.parquet\"\n",
    "output_path = \"gadm_emissions/gadm_2\"\n",
    "batch_count = 0\n",
    "total_rows = 0\n",
    "\n",
    "print(\"executing gadm_2 query...\")\n",
    "\n",
    "# Fetch first batch\n",
    "rows = cur.fetchmany(batch_size)\n",
    "if not rows:\n",
    "    raise Exception(\"No data returned from query.\")\n",
    "\n",
    "field_names = [desc[0] for desc in cur.description]\n",
    "first_table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "writer = pq.ParquetWriter(output_file, first_table.schema)\n",
    "writer.write_table(first_table)\n",
    "batch_count += 1\n",
    "total_rows += len(rows)\n",
    "print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "# Process remaining batches\n",
    "while True:\n",
    "    rows = cur.fetchmany(batch_size)\n",
    "    if not rows:\n",
    "        break\n",
    "\n",
    "    table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "    table = table.cast(writer.schema)  # ensure schema matches first batch\n",
    "    writer.write_table(table)\n",
    "\n",
    "    batch_count += 1\n",
    "    total_rows += len(rows)\n",
    "    print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "writer.close()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "split_or_move_parquet(output_file, output_path)\n",
    "\n",
    "print(\"Successfully refreshed GADM_2 data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c14e646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query...\n",
      "‚úÖ File city_emissions.parquet was 25.7 MB, moved to city_emissions/city_emissions.parquet\n",
      "Successfuly refreshed city_emissions data.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ City Emissions ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/city_emissions.parquet\"\n",
    "output_path = \"city_emissions\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE city_emissions_parquet AS\n",
    "    \n",
    "\tselect extract(year from start_time) as year\n",
    "\t\t, ce.city_id\n",
    "\t\t, cb.name as city_name\n",
    "\t\t, cb.corrected_name as corrected_name\n",
    "\t\t, ce.iso3_country\n",
    "\t\t, ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ce.original_inventory_sector as subsector\n",
    "        , itm.activity_is_temporal\n",
    "\t\t, case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "\t\t, sum(asset_emissions) asset_emissions\n",
    "\t\t, case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "\t\t, sum(remainder_emissions) remainder_emissions\n",
    "\t\t, sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "\tfrom postgres_scan('{postgres_url}','public', 'city_emissions') ce\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'city_boundaries') cb\n",
    "\t\ton cb.city_id = ce.city_id\n",
    "        and cb.reporting_entity = 'ghs-fua'\n",
    "\tleft join (\n",
    "\t\tselect distinct sector, subsector\n",
    "\t\tfrom postgres_scan('{postgres_url}','public', 'asset_schema')\n",
    "\t) asch\n",
    "\t\ton cast(asch.subsector as varchar) = cast(ce.original_inventory_sector as varchar)\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(ce.iso3_country as varchar)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "         on itm.original_inventory_sector = ce.original_inventory_sector\n",
    "\n",
    "\twhere extract(year from ce.start_time) = 2024\n",
    "\t\tand ce.gas = 'co2e_100yr'\n",
    "        and cb.city_id is not null\n",
    "\n",
    "\tgroup by extract(year from start_time) \n",
    "\t\t, ce.city_id\n",
    "\t\t, cb.name \n",
    "\t\t, cb.corrected_name \n",
    "\t\t, ce.iso3_country\n",
    "\t\t, ca.name \n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "\t\t, asch.sector\n",
    "\t\t, ce.original_inventory_sector\n",
    "        , itm.activity_is_temporal;\n",
    "            \n",
    "    COPY city_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "# and ce.original_inventory_sector not in ('forest-land-clearing',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-degradation',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-fires',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-forest-land',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-shrubgrass',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-wetland',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'removals',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'shrubgrass-fires',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'water-reservoirs',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'wetland-fires')\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfuly refreshed city_emissions data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb613882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query...\n",
      "‚úÖ File asset_ownership.parquet was 7.5 MB, moved to ownership/asset_ownership.parquet\n",
      "Successfully refreshed ownership data.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ Asset Ownership ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/asset_ownership.parquet\"\n",
    "output_path = \"ownership\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE asset_ownership_parquet AS\n",
    "            \n",
    "    SELECT *\n",
    "    FROM postgres_scan('{postgres_url}','public', 'asset_ownership');\n",
    "    \n",
    "    COPY asset_ownership_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed ownership data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ea692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query...\n",
      "‚úÖ File deomgraphic.parquet was 1.6 MB, moved to demographic/deomgraphic.parquet\n",
      "Successfully refreshed ownership data.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------ Demographic ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/deomgraphic.parquet\"\n",
    "output_path = \"demographic\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE demographic_parquet AS\n",
    "            \n",
    "    select *\n",
    "    from postgres_scan('{postgres_url}', 'public', 'demographic_data')\n",
    "    where version = 'global_pop_2024_CN_1km_R2024B_UA_v1';\n",
    "    \n",
    "    COPY demographic_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed ownership data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c454e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data refresh complete!\n"
     ]
    }
   ],
   "source": [
    "print('Data refresh complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
