{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- LIBRARY IMPORTS AND FUNCTION DEFINITIONS ----------------------------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import sqlalchemy\n",
    "import sys, os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.utils import data_add_moer\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import psycopg2\n",
    "import shutil\n",
    "import gc\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "user = quote_plus(os.getenv(\"CLIMATETRACE_USER\"))\n",
    "password = quote_plus(os.getenv(\"CLIMATETRACE_PASS\"))\n",
    "host = os.getenv(\"CLIMATETRACE_HOST\")\n",
    "port = os.getenv(\"CLIMATETRACE_PORT\")\n",
    "database = os.getenv(\"CLIMATETRACE_DB\")\n",
    "\n",
    "postgres_url = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "\n",
    "def split_or_move_parquet(input_file, output_dir, target_size_mb=40):\n",
    "    \"\"\"\n",
    "    Splits a large Parquet file into ~target_size_mb chunks or moves it directly \n",
    "    to desdired folder if under the threshold.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input parquet file.\n",
    "        output_dir (str): Directory to save chunked (or moved) parquet files.\n",
    "        target_size_mb (int): Approx size limit per chunk in MB.\n",
    "    \"\"\"\n",
    "    input_file = Path(input_file)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_size_mb = input_file.stat().st_size / (1024 * 1024)\n",
    "\n",
    "    # If file is already below threshold, just move it\n",
    "    if file_size_mb <= target_size_mb:\n",
    "        dest_file = output_dir / input_file.name\n",
    "        shutil.move(str(input_file), dest_file)\n",
    "        print(f\"âœ… File {input_file.name} was {file_size_mb:.1f} MB, moved to {dest_file}\")\n",
    "        return\n",
    "\n",
    "    print(f\"âš¡ Splitting {input_file.name} ({file_size_mb:.1f} MB)...\")\n",
    "\n",
    "    # Load full Parquet into DataFrame\n",
    "    df = pd.read_parquet(input_file)\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Estimate bytes per row\n",
    "    test_sample = df.iloc[:min(10000, total_rows)]\n",
    "    test_table = pa.Table.from_pandas(test_sample)\n",
    "    pq.write_table(test_table, \"temp.parquet\")\n",
    "    bytes_per_row = os.path.getsize(\"temp.parquet\") / len(test_sample)\n",
    "    os.remove(\"temp.parquet\")\n",
    "\n",
    "    # Rows per chunk\n",
    "    target_bytes = target_size_mb * 1024 * 1024\n",
    "    rows_per_chunk = max(1, int(target_bytes / bytes_per_row))\n",
    "\n",
    "    # Split and write\n",
    "    for i, start in enumerate(range(0, total_rows, rows_per_chunk)):\n",
    "        end = min(start + rows_per_chunk, total_rows)\n",
    "        chunk_df = df.iloc[start:end]\n",
    "        chunk_table = pa.Table.from_pandas(chunk_df)\n",
    "        output_path = output_dir / f\"{input_file.stem}_chunk_{i+1}.parquet\"\n",
    "        pq.write_table(chunk_table, output_path)\n",
    "        size_mb = output_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - Saved {output_path} ({size_mb:.1f} MB, rows {start}â€“{end})\")\n",
    "\n",
    "    # Delete original after chunking\n",
    "    input_file.unlink()\n",
    "    print(f\"ðŸ—‘ï¸ Deleted original {input_file.name}\")\n",
    "    print(\"âœ… Splitting complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------- ARCHIVE THE EXISTING DATA ----------------------------------\n",
    "\n",
    "\n",
    "def archive_parquets(data_folder_name='data', archive_folder_name='zzz_archive'):\n",
    "\n",
    "    \"\"\"\n",
    "    Recursively finds ALL .parquet files under /data (at any depth),\n",
    "    excluding certain root-level folders, and moves them to zzz_archive.\n",
    "    Existing parquets in zzz_archive are removed before copying.\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = Path.cwd()\n",
    "    archive_dir = data_dir / archive_folder_name\n",
    "\n",
    "    # Root-level folders/files to ignore\n",
    "    ignore_list = {\n",
    "        'percentile_moer',\n",
    "        'raw_csvs',\n",
    "        'strategy',\n",
    "        'zzz_archive',\n",
    "        'zzz_landing_zone',\n",
    "        'README.md',\n",
    "        'refresh_data.ipynb'\n",
    "    }\n",
    "\n",
    "    # ----- DELETE existing parquets in archive -----\n",
    "    print(\"Clearing zzz_archive...\")\n",
    "    for f in archive_dir.glob(\"*.parquet\"):\n",
    "        f.unlink()\n",
    "        print(f\"Deleted old parquet: {f.name}\")\n",
    "\n",
    "    # ----- RECURSIVELY FIND ALL PARQUETS -----\n",
    "    print(\"\\nScanning for parquet files...\\n\")\n",
    "\n",
    "    # Walk EVERY file in /data recursively\n",
    "    for parquet_file in data_dir.rglob(\"*.parquet\"):\n",
    "\n",
    "        # Skip files **inside** ignored root-level directories\n",
    "        parts = parquet_file.relative_to(data_dir).parts\n",
    "\n",
    "        # parts[0] is the top-level folder name\n",
    "        if parts and parts[0] in ignore_list:\n",
    "            # skip parquets inside ignored dirs\n",
    "            continue\n",
    "\n",
    "        # Skip archive folder (we just cleared it)\n",
    "        if archive_folder_name in parquet_file.parts:\n",
    "            continue\n",
    "\n",
    "        # Destination in archive\n",
    "        dest = archive_dir / parquet_file.name\n",
    "\n",
    "        # Move + overwrite if needed (archive is already emptied)\n",
    "        shutil.move(str(parquet_file), str(dest))\n",
    "        print(f\"Moved: {parquet_file} â†’ {dest}\")\n",
    "\n",
    "    print(\"\\nâœ¨ Complete: All parquet files archived. âœ¨\")\n",
    "\n",
    "\n",
    "archive_parquets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script takes CSVs dropped into data/zzz_landing_zone,\n",
    "routes them based on filename, and converts them into Parquet.\n",
    "If the new parquet is larger than 45MB, it will be split into \n",
    "smaller chunks before routing to its destination folder.\n",
    "\n",
    "âš ï¸ Only processes .csv files\n",
    "\"\"\"\n",
    "\n",
    "input_dir = Path(\"zzz_landing_zone\")\n",
    "output_base = Path(\"statistics\")\n",
    "\n",
    "routing_map = {\n",
    "    \"country_subsector_emissions_statistics\": \"country_subsector_emissions_statistics\",\n",
    "    \"country_subsector_emissions_totals\": \"country_subsector_emissions_totals\",\n",
    "    \"gadm_1_emissions_statistics\": \"gadm_1_emissions_statistics\"\n",
    "}\n",
    "\n",
    "# Ensure output subfolders exist\n",
    "for subfolder in routing_map.values():\n",
    "    (output_base / subfolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process only CSVs\n",
    "for csv_file in input_dir.glob(\"*.csv\"):\n",
    "    print(f\"Converting {csv_file.name}...\")\n",
    "\n",
    "    # Convert CSV â†’ Parquet in landing zone\n",
    "    df = pd.read_csv(csv_file)\n",
    "    parquet_file = input_dir / csv_file.with_suffix(\".parquet\").name\n",
    "    df.to_parquet(parquet_file, engine=\"pyarrow\", index=False)\n",
    "    print(f\"âœ… Converted {csv_file.name} â†’ {parquet_file.name} in landing zone\")\n",
    "\n",
    "    # Delete original CSV\n",
    "    csv_file.unlink()\n",
    "    print(f\"ðŸ—‘ï¸ Deleted original CSV: {csv_file.name}\")\n",
    "\n",
    "    # Route Parquet into correct stats subfolder (split if needed)\n",
    "    destination = None\n",
    "    for pattern, subfolder in routing_map.items():\n",
    "        if pattern in parquet_file.name:\n",
    "            destination = output_base / subfolder\n",
    "            break\n",
    "\n",
    "    if destination:\n",
    "        split_or_move_parquet(parquet_file, destination)\n",
    "    else:\n",
    "        print(f\"âš ï¸ No matching subfolder for {parquet_file.name}, skipping.\")\n",
    "\n",
    "print(\"ðŸŽ‰ CSV to Parquet + routing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ------------ THIS NEEDS TO BE FIXED AND PROBABLY BE STORED AT ASSET LEVEL... TRY CALCULATING AT ASSET LEVEL FIRST\n",
    "# 2. CHECK OTHER TABLES FOR TEMP GRAIN (GADM & CITY)\n",
    "\n",
    "# ------------------------------------- ASSET EMISSIONS COUNTRY SUBSECTOR LEVEL -------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/asset_emissions_country_subsector.parquet\"\n",
    "output_path = \"asset_emissions/country_subsector_level\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print(\"Getting max month...\")\n",
    "max_date = con.execute(f\"\"\"\n",
    "    select max(start_time)\n",
    "    from postgres_scan('{postgres_url}', 'public', 'asset_emissions')                       \n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "print(\"Aggregating assets to subsector-level and writing to parquet file, this may take a while...\")\n",
    "con.execute(f\"\"\"\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE asset_emissions_parquet AS\n",
    "    SELECT ae.iso3_country,\n",
    "        ae.original_inventory_sector,\n",
    "        itm.activity_is_temporal,\n",
    "        ae.start_time,\n",
    "        ae.gas,\n",
    "        sch.sector,\n",
    "        ca.name as country_name,\n",
    "        ca.continent,\n",
    "        ca.unfccc_annex,\n",
    "        ca.em_finance,\n",
    "        ca.g20,\n",
    "        ca.eu,\n",
    "        ca.oecd,\n",
    "        ca.developed_un,\n",
    "        ae.release,\n",
    "        sum(emissions_quantity) emissions_quantity,\n",
    "        case when activity_is_temporal = true then sum(activity) else avg(activity) end as activity,\n",
    "        sum(emissions_quantity) / sum(activity) weighted_average_emissions_factor\n",
    "    \n",
    "    FROM postgres_scan('{postgres_url}', 'public', 'asset_emissions') ae\n",
    "    LEFT JOIN postgres_scan('{postgres_url}', 'public', 'country_analysis') ca\n",
    "        ON CAST(ca.iso3_country AS VARCHAR) = CAST(ae.iso3_country AS VARCHAR)\n",
    "    LEFT JOIN (\n",
    "        SELECT DISTINCT sector, subsector FROM postgres_scan('{postgres_url}', 'public', 'asset_schema')\n",
    "    ) sch\n",
    "        ON CAST(sch.subsector AS VARCHAR) = CAST(ae.original_inventory_sector AS VARCHAR)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "        on itm.original_inventory_sector = ae.original_inventory_sector\n",
    "    \n",
    "    WHERE ae.start_time >= (\n",
    "                date_trunc('year', DATE '{max_date}') - INTERVAL '3 YEARS'\n",
    "            )\n",
    "      AND ae.gas in ('co2e_100yr','ch4')\n",
    "      AND ae.most_granular = TRUE\n",
    "    \n",
    "    GROUP BY ae.iso3_country,\n",
    "        ae.original_inventory_sector,\n",
    "        itm.activity_is_temporal,\n",
    "        ae.start_time,\n",
    "        ae.gas,\n",
    "        sch.sector,\n",
    "        ca.name,\n",
    "        ca.continent,\n",
    "        ca.unfccc_annex,\n",
    "        ca.em_finance,\n",
    "        ca.g20,\n",
    "        ca.eu,\n",
    "        ca.oecd,\n",
    "        ca.developed_un,\n",
    "        ae.release;\n",
    "\n",
    "    COPY asset_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print(\"âœ… Asset parquet file exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ Asset Annual Emissions ------------------------------------\n",
    "\n",
    "################### CURRENTLY USING DATA FUSION TABLES, NEEDS TO BE CHANGED BACK WHEN READY\n",
    "from sqlalchemy import text\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/asset_annual_emissions.parquet\"\n",
    "\n",
    "engine = sqlalchemy.create_engine(postgres_url)\n",
    "\n",
    "\n",
    "print('Query Running: Aggregating asset data to annual level and adding ERS...')\n",
    "query = f'''\n",
    "\n",
    "\t\tselect extract(year from ae.start_time) as year\n",
    "\t\t\t, cast(ae.asset_id as text) as asset_id\n",
    "\t\t\t, ai.asset_type\n",
    "\t\t\t, CASE \n",
    "\t\t\t\t\tWHEN ae.original_inventory_sector = 'iron-and-steel' AND ai.asset_type LIKE '%BF%' \n",
    "\t\t\t\t\t\tTHEN '{{''iron-and-steel'': [''BF'', ''DRI-EAF'']}}'\n",
    "\t\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Refinery%' \n",
    "\t\t\t\t\t\tTHEN '{{''aluminum'': [''Refinery'']}}'\n",
    "\t\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Smelting%' \n",
    "\t\t\t\t\t\tTHEN '{{''aluminum'': [''Smelting'']}}'\n",
    "\t\t\t\t\tELSE 'all' \n",
    "\t\t\t\tEND AS asset_type_2\n",
    "\t\t\t, ai.asset_name\n",
    "\t\t\t, ae.iso3_country\n",
    "\t\t\t, ca.name as country_name\n",
    "\t\t\t, abc.region balancing_authority_region\n",
    "\t\t\t, ca.continent\n",
    "\t\t\t, ca.eu\n",
    "\t\t\t, ca.oecd\n",
    "\t\t\t, ca.unfccc_annex\n",
    "\t\t\t, ca.developed_un\n",
    "\t\t\t, ca.em_finance\n",
    "            , ca.g20\n",
    "\t\t\t, asch.sector\n",
    "\t\t\t, ae.original_inventory_sector as subsector\n",
    "            , itm.capacity_is_temporal\n",
    "\t\t\t, itm.activity_is_temporal\n",
    "\t\t\t, ST_AsText(al.location) as lat_lon\n",
    "\t\t\t, al.gadm_1\n",
    "\t\t\t, al.gadm_2\n",
    "            , ae.most_granular\n",
    "\t\t\t, al.ghs_fua\n",
    "\t\t\t, al.city_id\n",
    "\t\t\t, ae.other1\n",
    "\t\t\t, ae.other2\n",
    "\t\t\t, ae.other3\n",
    "\t\t\t, ae.other4\n",
    "\t\t\t, ae.other5\n",
    "\t\t\t, ae.other6\n",
    "\t\t\t, ae.other7\n",
    "\t\t\t, ae.other8\n",
    "\t\t\t, ae.other9\n",
    "\t\t\t, ae.other10\n",
    "\t\t\t, ae.activity_units\n",
    "\t\t\t, case when capacity_is_temporal = true then sum(capacity) else avg(capacity) end as capacity\n",
    "\t\t\t, case when activity_is_temporal = true then sum(activity) else avg(activity) end as activity\n",
    "\t\t\t, avg(emissions_factor) average_emissions_factor\n",
    "\t\t\t, sum(emissions_quantity) emissions_quantity\n",
    "\t\t\t, 'asset' as reduction_q_type\n",
    "\t\t\t, ers.strategy_id\n",
    "\t\t\t, ers.strategy_name\n",
    "\t\t\t, ers.strategy_description\n",
    "\t\t\t, ers.mechanism\n",
    "\t\t\t, ers.old_activity\n",
    "\t\t\t, ers.affected_activity\n",
    "\t\t\t, ers.old_emissions_factor\n",
    "\t\t\t, ers.new_emissions_factor\n",
    "\t\t\t, ers.emissions_reduced_at_asset\n",
    "\t\t\t, ers.induced_sector_1\n",
    "\t\t\t, ers.induced_sector_1_induced_emissions\n",
    "\t\t\t, ers.induced_sector_2\n",
    "\t\t\t, ers.induced_sector_2_induced_emissions\n",
    "\t\t\t, ers.induced_sector_3\n",
    "\t\t\t, ers.induced_sector_3_induced_emissions\n",
    "\t\t\t, ers.total_emissions_reduced_per_year\n",
    "            , ers.feasibility\n",
    "            , ers.feasibility_score\n",
    "            , ers.cost\n",
    "            , ers.cost_score\n",
    "            , ers.asset_rf_score\n",
    "            , ers.asset_difficulty_score\n",
    "\n",
    "\t\tfrom public.asset_emissions_data_fusion ae\n",
    "\t\tleft join public.asset_information_data_fusion ai\n",
    "\t\t\ton ai.asset_id = ae.asset_id\n",
    "\t\tleft join public.asset_location_data_fusion al\n",
    "\t\t\ton al.asset_id = ae.asset_id\n",
    "\t\tleft join (\n",
    "\t\t\tselect distinct sector, subsector from public.asset_schema\n",
    "\t\t) asch\n",
    "\t\t\ton cast(asch.subsector as varchar) = cast(ae.original_inventory_sector as varchar)\n",
    "\t\tleft join public.country_analysis ca\n",
    "\t\t\ton cast(ca.iso3_country as varchar) = cast(ae.iso3_country as varchar)\n",
    "\t\tleft join public.asset_ba_crosswalk abc\n",
    "\t\t\ton cast(abc.asset_id as text) = cast(ae.asset_id as text)\n",
    "\t\tleft join (\n",
    "\t\t\tselect rdf.* \n",
    "\t\t\tfrom public.reductions_data_fusion rdf\n",
    "\t\t\twhere strategy_rank = 1\n",
    "\t\t\t\tand rdf.gas = 'co2e_100yr'\n",
    "\t\t) ers\n",
    "\t\t\ton ers.asset_id = ae.asset_id\n",
    "\t\tleft join public.is_temporal_map itm\n",
    "\t\t\ton cast(itm.original_inventory_sector as text) = cast(ae.original_inventory_sector as text)\n",
    "\n",
    "\t\twhere extract(year from ae.start_time) = 2024\n",
    "\t\t\tand ae.gas = 'co2e_100yr'\n",
    "\n",
    "\t\tgroup by extract(year from ae.start_time)\n",
    "\t\t\t, ae.asset_id\n",
    "\t\t\t, ai.asset_type\n",
    "\t\t\t, CASE \n",
    "\t\t\t\t\tWHEN ae.original_inventory_sector = 'iron-and-steel' AND ai.asset_type LIKE '%BF%' \n",
    "\t\t\t\t\t\tTHEN '{{''iron-and-steel'': [''BF'', ''DRI-EAF'']}}'\n",
    "\t\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Refinery%' \n",
    "\t\t\t\t\t\tTHEN '{{''aluminum'': [''Refinery'']}}'\n",
    "\t\t\t\t\tWHEN ae.original_inventory_sector = 'aluminum' AND ai.asset_type LIKE '%Smelting%' \n",
    "\t\t\t\t\t\tTHEN '{{''aluminum'': [''Smelting'']}}'\n",
    "\t\t\t\t\tELSE 'all' \n",
    "\t\t\t\tEND\n",
    "\t\t\t, ai.asset_name\n",
    "\t\t\t, ae.iso3_country\n",
    "\t\t\t, ca.name\n",
    "\t\t\t, abc.region\n",
    "\t\t\t, ca.continent\n",
    "\t\t\t, ca.eu\n",
    "\t\t\t, ca.oecd\n",
    "\t\t\t, ca.unfccc_annex\n",
    "\t\t\t, ca.developed_un\n",
    "\t\t\t, ca.em_finance\n",
    "            , ca.g20\n",
    "\t\t\t, asch.sector\n",
    "\t\t\t, ae.original_inventory_sector\n",
    "            , itm.capacity_is_temporal\n",
    "\t\t\t, itm.activity_is_temporal\n",
    "\t\t\t, ST_AsText(al.location)\n",
    "\t\t\t, al.gadm_1\n",
    "\t\t\t, al.gadm_2\n",
    "            , ae.most_granular\n",
    "\t\t\t, al.ghs_fua\n",
    "\t\t\t, al.city_id\n",
    "\t\t\t, ae.other1\n",
    "\t\t\t, ae.other2\n",
    "\t\t\t, ae.other3\n",
    "\t\t\t, ae.other4\n",
    "\t\t\t, ae.other5\n",
    "\t\t\t, ae.other6\n",
    "\t\t\t, ae.other7\n",
    "\t\t\t, ae.other8\n",
    "\t\t\t, ae.other9\n",
    "\t\t\t, ae.other10\n",
    "\t\t\t, ae.activity_units\n",
    "\t\t\t, ers.strategy_id\n",
    "\t\t\t, ers.strategy_name\n",
    "\t\t\t, ers.strategy_description\n",
    "\t\t\t, ers.mechanism\n",
    "\t\t\t, ers.old_activity\n",
    "\t\t\t, ers.affected_activity\n",
    "\t\t\t, ers.old_emissions_factor\n",
    "\t\t\t, ers.new_emissions_factor\n",
    "\t\t\t, ers.emissions_reduced_at_asset\n",
    "\t\t\t, ers.induced_sector_1\n",
    "\t\t\t, ers.induced_sector_1_induced_emissions\n",
    "\t\t\t, ers.induced_sector_2\n",
    "\t\t\t, ers.induced_sector_2_induced_emissions\n",
    "\t\t\t, ers.induced_sector_3\n",
    "\t\t\t, ers.induced_sector_3_induced_emissions\n",
    "\t\t\t, ers.total_emissions_reduced_per_year\n",
    "            , ers.feasibility\n",
    "            , ers.feasibility_score\n",
    "            , ers.cost\n",
    "            , ers.cost_score\n",
    "            , ers.asset_rf_score\n",
    "            , ers.asset_difficulty_score\n",
    "\t\t\t\n",
    "\t\t\tUNION ALL\n",
    "\t\t\t\n",
    "\t\t\tSELECT \n",
    "\t\t\t\t2024 AS year,\n",
    "\t\t\t\tasset_id,\n",
    "\t\t\t\tgr.asset_type,\n",
    "\t\t\t\tNULL AS asset_type_2,\n",
    "\t\t\t\tgr.asset_name,\n",
    "\t\t\t\tca.iso3_country,\n",
    "\t\t\t\tca.name AS country_name,\n",
    "\t\t\t\tNULL AS balancing_authority_region,\n",
    "\t\t\t\tca.continent,\n",
    "\t\t\t\tca.eu,\n",
    "\t\t\t\tca.oecd,\n",
    "\t\t\t\tca.unfccc_annex,\n",
    "\t\t\t\tca.developed_un,\n",
    "\t\t\t\tca.em_finance,\n",
    "                ca.g20,\n",
    "\t\t\t\tasch.sector,\n",
    "\t\t\t\tgr.original_inventory_sector AS subsector,\n",
    "                itm.capacity_is_temporal,\n",
    "\t\t\t\titm.activity_is_temporal,\n",
    "\t\t\t\tnull as lat_lon,\n",
    "\t\t\t\tCASE \n",
    "\t\t\t\t\tWHEN gb.admin_level = 1 THEN gb.gadm_id\n",
    "\t\t\t\t\tWHEN gb.admin_level = 2 THEN gb.immediate_parent \n",
    "\t\t\t\t\tELSE NULL \n",
    "\t\t\t\tEND AS gadm_1,\n",
    "\t\t\t\tCASE \n",
    "\t\t\t\t\tWHEN gb.admin_level = 2 THEN gb.gadm_id \n",
    "\t\t\t\t\tELSE NULL \n",
    "\t\t\t\tEND AS gadm_2,\n",
    "                true AS most_granular,\n",
    "\t\t\t\tNULL AS ghs_fua,\n",
    "\t\t\t\tNULL AS city_id,\n",
    "\t\t\t\tNULL AS other1,\n",
    "\t\t\t\tNULL AS other2,\n",
    "\t\t\t\tNULL AS other3,\n",
    "\t\t\t\tNULL AS other4,\n",
    "\t\t\t\tNULL AS other5,\n",
    "\t\t\t\tNULL AS other6,\n",
    "\t\t\t\tNULL AS other7,\n",
    "\t\t\t\tNULL AS other8,\n",
    "\t\t\t\tNULL AS other9,\n",
    "\t\t\t\tNULL AS other10,\n",
    "\t\t\t\tNULL AS activity_units,\n",
    "\t\t\t\t0 AS capacity,\n",
    "\t\t\t\t0 AS activity,\n",
    "\t\t\t\t0 AS average_emissions_factor,\n",
    "\t\t\t\t0 AS emissions_quantity,\n",
    "\t\t\t\t'remainder' AS reduction_q_type,\n",
    "\t\t\t\tgr.strategy_id,\n",
    "\t\t\t\tgr.strategy_name,\n",
    "\t\t\t\tgr.strategy_description,\n",
    "\t\t\t\tgr.mechanism,\n",
    "\t\t\t\tgr.old_activity,\n",
    "\t\t\t\tgr.affected_activity,\n",
    "\t\t\t\tgr.old_emissions_factor,\n",
    "\t\t\t\tgr.new_emissions_factor,\n",
    "\t\t\t\tgr.emissions_reduced_at_asset,\n",
    "\t\t\t\tgr.induced_sector_1,\n",
    "\t\t\t\tgr.induced_sector_1_induced_emissions,\n",
    "\t\t\t\tgr.induced_sector_2,\n",
    "\t\t\t\tgr.induced_sector_2_induced_emissions,\n",
    "\t\t\t\tgr.induced_sector_3,\n",
    "\t\t\t\tgr.induced_sector_3_induced_emissions,\n",
    "\t\t\t\tgr.total_emissions_reduced_per_year,\n",
    "                null as feasibility,\n",
    "\t\t\t\tnull as feasibility_score,\n",
    "\t\t\t\tnull as cost,\n",
    "\t\t\t\tnull as cost_score,\n",
    "\t\t\t\tnull as asset_rf_score,\n",
    "\t\t\t\tnull as asset_difficulty_score\n",
    "\t\t\t\n",
    "\t\t\tFROM public.gadm_reductions_data_fusion gr\n",
    "\t\t\tLEFT JOIN (\n",
    "\t\t\t\tselect distinct sector, subsector from public.asset_schema\n",
    "\t\t\t) asch\n",
    "\t\t\t\ton cast(asch.subsector as varchar) = cast(gr.original_inventory_sector as varchar)\n",
    "\t\t\tLEFT JOIN (\n",
    "\t\t\t\tselect distinct gadm_id, iso3_country, admin_level, immediate_parent\n",
    "\t\t\t\tfrom public.gadm_boundaries\n",
    "\t\t\t) gb\n",
    "\t\t\t\ton gb.gadm_id = gr.asset_id\n",
    "\t\t\tLEFT JOIN public.country_analysis ca\n",
    "\t\t\t\ton ca.iso3_country = gb.iso3_country\n",
    "\t\t\tLEFT JOIN public.is_temporal_map itm\n",
    "\t\t\t\ton cast(itm.original_inventory_sector as text) = cast(gr.original_inventory_sector as text)\n",
    "\t\t\t\t\n",
    "\t\t\tWHERE gr.strategy_rank = 1\n",
    "\t\t\t\tand gr.gas = 'co2e_100yr'\n",
    "                and total_emissions_reduced_per_year > 0\n",
    "                \n",
    "            UNION ALL\n",
    "\n",
    "            SELECT \n",
    "\t\t\t\t2024 AS year,\n",
    "\t\t\t\tasset_id,\n",
    "\t\t\t\tcr.asset_type,\n",
    "\t\t\t\tNULL AS asset_type_2,\n",
    "\t\t\t\tcr.asset_name,\n",
    "\t\t\t\tca.iso3_country,\n",
    "\t\t\t\tca.name AS country_name,\n",
    "\t\t\t\tNULL AS balancing_authority_region,\n",
    "\t\t\t\tca.continent,\n",
    "\t\t\t\tca.eu,\n",
    "\t\t\t\tca.oecd,\n",
    "\t\t\t\tca.unfccc_annex,\n",
    "\t\t\t\tca.developed_un,\n",
    "\t\t\t\tca.em_finance,\n",
    "                ca.g20,\n",
    "\t\t\t\tasch.sector,\n",
    "\t\t\t\tcr.original_inventory_sector AS subsector,\n",
    "                itm.capacity_is_temporal,\n",
    "\t\t\t\titm.activity_is_temporal,\n",
    "\t\t\t\tnull as lat_lon,\n",
    "\t\t\t\tnull AS gadm_1,\n",
    "\t\t\t\tNULL AS gadm_2,\n",
    "                false AS most_granular,\n",
    "\t\t\t\tarray[cr.asset_id] AS ghs_fua,\n",
    "\t\t\t\tcr.asset_id AS city_id,\n",
    "\t\t\t\tNULL AS other1,\n",
    "\t\t\t\tNULL AS other2,\n",
    "\t\t\t\tNULL AS other3,\n",
    "\t\t\t\tNULL AS other4,\n",
    "\t\t\t\tNULL AS other5,\n",
    "\t\t\t\tNULL AS other6,\n",
    "\t\t\t\tNULL AS other7,\n",
    "\t\t\t\tNULL AS other8,\n",
    "\t\t\t\tNULL AS other9,\n",
    "\t\t\t\tNULL AS other10,\n",
    "\t\t\t\tNULL AS activity_units,\n",
    "\t\t\t\t0 AS capacity,\n",
    "\t\t\t\t0 AS activity,\n",
    "\t\t\t\t0 AS average_emissions_factor,\n",
    "\t\t\t\t0 AS emissions_quantity,\n",
    "\t\t\t\t'remainder' AS reduction_q_type,\n",
    "\t\t\t\tcr.strategy_id,\n",
    "\t\t\t\tcr.strategy_name,\n",
    "\t\t\t\tcr.strategy_description,\n",
    "\t\t\t\tcr.mechanism,\n",
    "\t\t\t\tcr.old_activity,\n",
    "\t\t\t\tcr.affected_activity,\n",
    "\t\t\t\tcr.old_emissions_factor,\n",
    "\t\t\t\tcr.new_emissions_factor,\n",
    "\t\t\t\tcr.emissions_reduced_at_asset,\n",
    "\t\t\t\tcr.induced_sector_1,\n",
    "\t\t\t\tcr.induced_sector_1_induced_emissions,\n",
    "\t\t\t\tcr.induced_sector_2,\n",
    "\t\t\t\tcr.induced_sector_2_induced_emissions,\n",
    "\t\t\t\tcr.induced_sector_3,\n",
    "\t\t\t\tcr.induced_sector_3_induced_emissions,\n",
    "\t\t\t\tcr.total_emissions_reduced_per_year,\n",
    "                null as feasibility,\n",
    "\t\t\t\tnull as feasibility_score,\n",
    "\t\t\t\tnull as cost,\n",
    "\t\t\t\tnull as cost_score,\n",
    "\t\t\t\tnull as asset_rf_score,\n",
    "\t\t\t\tnull as asset_difficulty_score\n",
    "\t\t\t\n",
    "\t\t\tFROM public.city_reductions_data_fusion cr\n",
    "\t\t\tLEFT JOIN (\n",
    "\t\t\t\tselect distinct sector, subsector from public.asset_schema\n",
    "\t\t\t) asch\n",
    "\t\t\t\ton cast(asch.subsector as varchar) = cast(cr.original_inventory_sector as varchar)\n",
    "\n",
    "            ------ CHANGE THIS JOIN AHHHHHHH ------    \n",
    "\t\t\tLEFT JOIN (\n",
    "\t\t\t\tselect distinct city_id, iso3_country\n",
    "\t\t\t\tfrom public.city_boundaries\n",
    "\t\t\t) cb\n",
    "\t\t\t\ton cb.city_id = cr.asset_id\n",
    "                \n",
    "            \n",
    "\t\t\tLEFT JOIN public.country_analysis ca\n",
    "\t\t\t\ton ca.iso3_country = cb.iso3_country\n",
    "\t\t\tLEFT JOIN public.is_temporal_map itm\n",
    "\t\t\t\ton cast(itm.original_inventory_sector as text) = cast(cr.original_inventory_sector as text)\n",
    "\t\t\t\t\n",
    "\t\t\tWHERE cr.strategy_rank = 1\n",
    "\t\t\t\tand cr.gas = 'co2e_100yr'\n",
    "                and total_emissions_reduced_per_year > 0\n",
    "                and asset_id not like '%_EXT'\n",
    "        ;     \n",
    "    '''\n",
    "\n",
    "# print(query)\n",
    "\n",
    "df = pd.read_sql_query(text(query), engine)\n",
    "\n",
    "df.to_parquet(parquet_path, index=False)\n",
    "# removing forestry sectors from query\n",
    "\t\t# and ae.original_inventory_sector not in ('forest-land-clearing',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'forest-land-degradation',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'forest-land-fires',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'net-forest-land',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'net-shrubgrass',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'net-wetland',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'removals',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'shrubgrass-fires',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'water-reservoirs',\n",
    "\t\t# \t\t\t\t\t\t\t\t\t\t\t'wetland-fires')\n",
    "\n",
    "#  con.close()\n",
    "\n",
    "## ---------------------------------- ADD MOER FACTORS --------------------------------------\n",
    "parquet_path = Path('zzz_landing_zone/asset_annual_emissions.parquet')\n",
    "landing_zone_path = Path('zzz_landing_zone/asset_annual_emissions_moer.parquet')\n",
    "# output_path =  Path('asset_emissions/asset_level_2024')\n",
    "\n",
    "df_asset = pd.read_parquet(parquet_path)\n",
    "\n",
    "# adding moer data to assets\n",
    "asset_moer_df = data_add_moer(df_asset, cond={\"moer\": True})\n",
    "\n",
    "# converting data to new parquet file\n",
    "asset_moer_df.to_parquet(landing_zone_path, index=False)\n",
    "\n",
    "# freeing up memory\n",
    "print(\"Deleting asset-moer dataframes to free up memory.\")\n",
    "del df_asset\n",
    "del asset_moer_df\n",
    "gc.collect()\n",
    "\n",
    "# # deleting original asset file\n",
    "parquet_path.unlink()\n",
    "print(\"Original asset file deleted\")\n",
    "\n",
    "# print(\"Aggregating Asset Data\")\n",
    "\n",
    "con.close()\n",
    "\n",
    "\n",
    "# # splitting asset data into chunks\n",
    "# split_or_move_parquet(landing_zone_path, output_path)\n",
    "\n",
    "# print(\"Successfully updated asset_level data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f7c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moer_path = Path('zzz_landing_zone/asset_annual_emissions_moer.parquet')\n",
    "agg_path = Path('zzz_landing_zone/asset_aggregated.parquet')\n",
    "output_path = Path('asset_emissions/asset_level_2024')\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "con.execute(f'''\n",
    "            create table asset_aggregated as\n",
    "            select year\n",
    "                , asset_id\n",
    "                , asset_type\n",
    "                , asset_type_2\n",
    "                , asset_name\n",
    "                , iso3_country\n",
    "                , country_name\n",
    "                , balancing_authority_region\n",
    "                , continent\n",
    "                , eu\n",
    "                , oecd\n",
    "                , unfccc_annex\n",
    "                , developed_un\n",
    "                , em_finance\n",
    "                , g20\n",
    "                , sector\n",
    "                , subsector\n",
    "                , capacity_is_temporal\n",
    "                , activity_is_temporal\n",
    "                , lat_lon\n",
    "                , gadm_1\n",
    "                , gadm_2\n",
    "                , most_granular\n",
    "                , ghs_fua\n",
    "                , city_id\n",
    "                , activity_units\n",
    "                , case when capacity_is_temporal = true then sum(capacity) else avg(capacity) end as capacity\n",
    "                , case when activity_is_temporal = true then sum(activity) else avg(activity) end as activity\n",
    "                , avg(average_emissions_factor) average_emissions_factor\n",
    "                , sum(emissions_quantity) emissions_quantity\n",
    "                , reduction_q_type\n",
    "                , strategy_id\n",
    "                , strategy_name\n",
    "                , strategy_description\n",
    "                , mechanism\n",
    "                , old_activity\n",
    "                , affected_activity\n",
    "                , old_emissions_factor\n",
    "                , new_emissions_factor\n",
    "                , emissions_reduced_at_asset\n",
    "                , induced_sector_1\n",
    "                , induced_sector_1_induced_emissions\n",
    "                , induced_sector_2\n",
    "                , induced_sector_2_induced_emissions\n",
    "                , induced_sector_3\n",
    "                , induced_sector_3_induced_emissions\n",
    "                , total_emissions_reduced_per_year\n",
    "                , feasibility\n",
    "                , feasibility_score\n",
    "                , cost\n",
    "                , cost_score\n",
    "                , asset_rf_score\n",
    "                , asset_difficulty_score\n",
    "                , avg(ef_moer) ef_moer\n",
    "                , sum(eq_12) eq_12\n",
    "                , avg(ef_12) ef_12\n",
    "                , sum(eq_12_moer) eq_12_moer\n",
    "                , avg(ef_12_moer) ef_12_moer\n",
    "                \n",
    "            from '{moer_path}'\n",
    "\n",
    "            group by year\n",
    "                , asset_id\n",
    "                , asset_type\n",
    "                , asset_type_2\n",
    "                , asset_name\n",
    "                , iso3_country\n",
    "                , country_name\n",
    "                , balancing_authority_region\n",
    "                , continent\n",
    "                , eu\n",
    "                , oecd\n",
    "                , unfccc_annex\n",
    "                , developed_un\n",
    "                , em_finance\n",
    "                , g20\n",
    "                , sector\n",
    "                , subsector\n",
    "                , capacity_is_temporal\n",
    "                , activity_is_temporal\n",
    "                , lat_lon\n",
    "                , gadm_1\n",
    "                , gadm_2\n",
    "                , most_granular\n",
    "                , ghs_fua\n",
    "                , city_id\n",
    "                , activity_units\n",
    "                , reduction_q_type\n",
    "                , strategy_id\n",
    "                , strategy_name\n",
    "                , strategy_description\n",
    "                , mechanism\n",
    "                , old_activity\n",
    "                , affected_activity\n",
    "                , old_emissions_factor\n",
    "                , new_emissions_factor\n",
    "                , emissions_reduced_at_asset\n",
    "                , induced_sector_1\n",
    "                , induced_sector_1_induced_emissions\n",
    "                , induced_sector_2\n",
    "                , induced_sector_2_induced_emissions\n",
    "                , induced_sector_3\n",
    "                , induced_sector_3_induced_emissions\n",
    "                , total_emissions_reduced_per_year\n",
    "                , feasibility\n",
    "                , feasibility_score\n",
    "                , cost\n",
    "                , cost_score\n",
    "                , asset_rf_score\n",
    "                , asset_difficulty_score\n",
    "            ;\n",
    "\n",
    "            COPY asset_aggregated to '{agg_path}' (FORMAT PARQUET);\n",
    "            \n",
    "            ''')\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(agg_path, output_path)\n",
    "\n",
    "moer_path.unlink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c799bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------------------------- Uncomment and run this if you created the file in the block above, but couldn't get it to split and moved to the correct folder\n",
    "\n",
    "# parquet_path = Path('zzz_landing_zone/asset_annual_emissions.parquet')\n",
    "# landing_zone_path = Path('zzz_landing_zone/asset_annual_emissions_moer.parquet')\n",
    "# output_path =  Path('asset_emissions/asset_level_2024')\n",
    "\n",
    "# df_asset = pd.read_parquet(parquet_path)\n",
    "\n",
    "# # adding moer data to assets\n",
    "# asset_moer_df = data_add_moer(df_asset, cond={\"moer\": True})\n",
    "\n",
    "# # converting data to new parquet file\n",
    "# asset_moer_df.to_parquet(landing_zone_path, index=False)\n",
    "\n",
    "# freeing up memory\n",
    "# print(\"Deleting asset-moer dataframes to free up memory.\")\n",
    "# del df_asset\n",
    "# del asset_moer_df\n",
    "# gc.collect()\n",
    "\n",
    "# deleting original asset file\n",
    "# parquet_path.unlink()\n",
    "# print(\"Original asset file deleted\")\n",
    "\n",
    "# # splitting asset data into chunks\n",
    "# split_or_move_parquet(landing_zone_path, output_path)\n",
    "\n",
    "# print(\"Successfully updated asset_level data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ GADM_0 Emissions ------------------------------------\n",
    "\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/gadm_0_emissions.parquet\"\n",
    "output_path = \"gadm_emissions/gadm_0\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print('Running query')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE gadm_0_emissions_parquet AS\n",
    "    select extract(year from g0e.start_time) as year \n",
    "        , g0e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g0e.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , gb.name gadm_0_name\n",
    "        , gb.corrected_name gadm_0_corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "        , asch.sector\n",
    "        , g0e.original_inventory_sector subsector\n",
    "        , itm.activity_is_temporal\n",
    "        , g0e.gas\n",
    "        , case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from postgres_scan('{postgres_url}', 'public', 'gadm_0_emissions') g0e\n",
    "    left join (\n",
    "        select distinct gadm_id\n",
    "            , gid\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from postgres_scan('{postgres_url}','public', 'gadm_boundaries') \n",
    "        where admin_level = 0\n",
    "    ) as gb\n",
    "        on g0e.gadm_id = gb.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from postgres_scan('{postgres_url}','public', 'asset_schema') \n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(g0e.original_inventory_sector as varchar)\n",
    "    left join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(g0e.iso3_country as varchar)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "         on itm.original_inventory_sector = g0e.original_inventory_sector\n",
    "\n",
    "    where g0e.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "        \n",
    "    group by extract(year from g0e.start_time) \n",
    "        , g0e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g0e.iso3_country\n",
    "        , ca.name\n",
    "        , gb.name \n",
    "        , gb.corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "        , asch.sector\n",
    "        , g0e.original_inventory_sector\n",
    "        , itm.activity_is_temporal\n",
    "        , g0e.gas;\n",
    "\n",
    "    COPY gadm_0_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "\n",
    "# and g0e.original_inventory_sector not in ('forest-land-clearing',\n",
    "#                                                 'forest-land-degradation',\n",
    "#                                                 'forest-land-fires',\n",
    "#                                                 'net-forest-land',\n",
    "#                                                 'net-shrubgrass',\n",
    "#                                                 'net-wetland',\n",
    "#                                                 'removals',\n",
    "#                                                 'shrubgrass-fires',\n",
    "#                                                 'water-reservoirs',\n",
    "#                                                 'wetland-fires')\n",
    "\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed GADM_0 data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8defd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------ GADM 1 Emissions ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/gadm_1_emissions.parquet\"\n",
    "output_path = \"gadm_emissions/gadm_1\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "print('Running query')\n",
    "con.execute(f'''\n",
    "    INSTALL postgres;\n",
    "    LOAD postgres;\n",
    "\n",
    "    CREATE TABLE gadm_1_emissions_parquet AS\n",
    "    select extract(year from g1e.start_time) as year \n",
    "        , g1e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g1e.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , gb.name gadm_1_name\n",
    "        , gb.corrected_name gadm_1_corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "        , asch.sector\n",
    "        , g1e.original_inventory_sector subsector\n",
    "        , itm.activity_is_temporal\n",
    "        , g1e.gas\n",
    "        , case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from postgres_scan('{postgres_url}', 'public', 'gadm_1_emissions') g1e\n",
    "    left join (\n",
    "        select distinct gadm_id\n",
    "            , gid\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from postgres_scan('{postgres_url}','public', 'gadm_boundaries') \n",
    "        where admin_level = 1\n",
    "    ) as gb\n",
    "        on g1e.gadm_id = gb.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from postgres_scan('{postgres_url}','public', 'asset_schema') \n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(g1e.original_inventory_sector as varchar)\n",
    "    left join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(g1e.iso3_country as varchar)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "         on itm.original_inventory_sector = g1e.original_inventory_sector\n",
    "\n",
    "    where g1e.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "        \n",
    "\n",
    "    group by extract(year from g1e.start_time) \n",
    "        , g1e.gadm_id\n",
    "        , gb.gid\n",
    "        , gb.admin_level\n",
    "        , g1e.iso3_country\n",
    "        , ca.name\n",
    "        , gb.name \n",
    "        , gb.corrected_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "        , asch.sector\n",
    "        , g1e.original_inventory_sector\n",
    "        , itm.activity_is_temporal\n",
    "        , g1e.gas;\n",
    "\n",
    "    COPY gadm_1_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "''')\n",
    "\n",
    "# and g1e.original_inventory_sector not in ('forest-land-clearing',\n",
    "#                                                 'forest-land-degradation',\n",
    "#                                                 'forest-land-fires',\n",
    "#                                                 'net-forest-land',\n",
    "#                                                 'net-shrubgrass',\n",
    "#                                                 'net-wetland',\n",
    "#                                                 'removals',\n",
    "#                                                 'shrubgrass-fires',\n",
    "#                                                 'water-reservoirs',\n",
    "#                                                 'wetland-fires')\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed GADM_1 data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04194ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------- GADM 2 BATCH -----------------------------------------------------------------\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    dbname=database,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    host=host,\n",
    "    port=port\n",
    ")\n",
    "\n",
    "cur = conn.cursor(name='parquet_cursor')  # server-side cursor\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "     select extract(year from ge.start_time) as year \n",
    "        , gb1.gadm_id gadm_1_id\n",
    "        , gb1.name gadm_1_name\n",
    "        , gb1.corrected_name gadm_1_corrected_name\n",
    "        , ge.gadm_id gadm_2_id\n",
    "        , gb2.name gadm_2_name\n",
    "        , gb2.corrected_name gadm_2_corrected_name\n",
    "        , gb2.gid\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector subsector\n",
    "        , itm.activity_is_temporal\n",
    "        , case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "        , sum(asset_emissions) asset_emissions\n",
    "        , case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "        , sum(remainder_emissions) remainder_emissions\n",
    "        , sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "    from gadm_emissions ge\n",
    "    inner join (\n",
    "        select distinct gadm_id\n",
    "            , gid\n",
    "            , immediate_parent\n",
    "            , name\n",
    "            , corrected_name\n",
    "            , admin_level\n",
    "        from gadm_boundaries\n",
    "        where admin_level = 2\n",
    "    ) as gb2\n",
    "        on ge.gadm_id = gb2.gadm_id\n",
    "    left join (\n",
    "        select distinct sector\n",
    "            , subsector\n",
    "        from asset_schema\n",
    "    ) asch\n",
    "        on cast(asch.subsector as varchar) = cast(ge.original_inventory_sector as varchar)\n",
    "    left join (\n",
    "        select gadm_id\n",
    "            , name\n",
    "            , corrected_name\n",
    "        from gadm_boundaries\n",
    "        where admin_level = 1\n",
    "    ) gb1\n",
    "        on gb1.gadm_id = gb2.immediate_parent\n",
    "    left join country_analysis ca\n",
    "        on cast(ca.iso3_country as varchar) = cast(ge.iso3_country as varchar)\n",
    "    left join is_temporal_map itm\n",
    "        on itm.original_inventory_sector = cast(ge.original_inventory_sector as text)\n",
    "\n",
    "    where ge.gas = 'co2e_100yr'\n",
    "        and extract(year from start_time) = 2024\n",
    "\n",
    "\n",
    "    group by extract(year from ge.start_time)\n",
    "        , gb1.gadm_id \n",
    "        , gb1.name\n",
    "        , gb1.corrected_name\n",
    "        , ge.gadm_id \n",
    "        , gb2.name\n",
    "        , gb2.corrected_name\n",
    "        , gb2.gid\n",
    "        , gb2.admin_level\n",
    "        , ge.iso3_country\n",
    "        , ca.name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "        , asch.sector\n",
    "        , ge.original_inventory_sector\n",
    "        , itm.activity_is_temporal\n",
    "    \"\"\")\n",
    "\n",
    "        # and ge.original_inventory_sector not in ('forest-land-clearing',\n",
    "        #                                         'forest-land-degradation',\n",
    "        #                                         'forest-land-fires',\n",
    "        #                                         'net-forest-land',\n",
    "        #                                         'net-shrubgrass',\n",
    "        #                                         'net-wetland',\n",
    "        #                                         'removals',\n",
    "        #                                         'shrubgrass-fires',\n",
    "        #                                         'water-reservoirs',\n",
    "        #                                         'wetland-fires')\n",
    "\n",
    "# Set up Parquet writer\n",
    "batch_size = 10000\n",
    "output_file = \"zzz_landing_zone/gadm_2_emissions.parquet\"\n",
    "output_path = \"gadm_emissions/gadm_2\"\n",
    "batch_count = 0\n",
    "total_rows = 0\n",
    "\n",
    "print(\"executing gadm_2 query...\")\n",
    "\n",
    "# Fetch first batch\n",
    "rows = cur.fetchmany(batch_size)\n",
    "if not rows:\n",
    "    raise Exception(\"No data returned from query.\")\n",
    "\n",
    "field_names = [desc[0] for desc in cur.description]\n",
    "first_table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "writer = pq.ParquetWriter(output_file, first_table.schema)\n",
    "writer.write_table(first_table)\n",
    "batch_count += 1\n",
    "total_rows += len(rows)\n",
    "print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "# Process remaining batches\n",
    "while True:\n",
    "    rows = cur.fetchmany(batch_size)\n",
    "    if not rows:\n",
    "        break\n",
    "\n",
    "    table = pa.Table.from_pylist([dict(zip(field_names, row)) for row in rows])\n",
    "    table = table.cast(writer.schema)  # ensure schema matches first batch\n",
    "    writer.write_table(table)\n",
    "\n",
    "    batch_count += 1\n",
    "    total_rows += len(rows)\n",
    "    print(f\"Processed batch {batch_count} ({len(rows)} rows), total rows: {total_rows}\")\n",
    "\n",
    "writer.close()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "split_or_move_parquet(output_file, output_path)\n",
    "\n",
    "print(\"Successfully refreshed GADM_2 data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ City Emissions ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/city_emissions.parquet\"\n",
    "output_path = \"city_emissions\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE city_emissions_parquet AS\n",
    "    \n",
    "\tselect extract(year from start_time) as year\n",
    "\t\t, ce.city_id\n",
    "\t\t, cb.name as city_name\n",
    "\t\t, cb.corrected_name as corrected_name\n",
    "\t\t, ce.iso3_country\n",
    "\t\t, ca.name as country_name\n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "\t\t, asch.sector\n",
    "\t\t, ce.original_inventory_sector as subsector\n",
    "        , itm.activity_is_temporal\n",
    "\t\t, case when activity_is_temporal = true then sum(asset_activity) else avg(asset_activity) end as asset_activity\n",
    "\t\t, sum(asset_emissions) asset_emissions\n",
    "\t\t, case when activity_is_temporal = true then sum(remainder_activity) else avg(remainder_activity) end as remainder_activity\n",
    "\t\t, sum(remainder_emissions) remainder_emissions\n",
    "\t\t, sum(asset_emissions) + sum(remainder_emissions) as emissions_quantity\n",
    "\n",
    "\tfrom postgres_scan('{postgres_url}','public', 'city_emissions') ce\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'city_boundaries') cb\n",
    "\t\ton cb.city_id = ce.city_id\n",
    "        and cb.reporting_entity = 'ghs-fua'\n",
    "\tleft join (\n",
    "\t\tselect distinct sector, subsector\n",
    "\t\tfrom postgres_scan('{postgres_url}','public', 'asset_schema')\n",
    "\t) asch\n",
    "\t\ton cast(asch.subsector as varchar) = cast(ce.original_inventory_sector as varchar)\n",
    "\tleft join postgres_scan('{postgres_url}','public', 'country_analysis') ca\n",
    "\t\ton cast(ca.iso3_country as varchar) = cast(ce.iso3_country as varchar)\n",
    "    left join postgres_scan('{postgres_url}', 'public', 'is_temporal_map') itm\n",
    "         on itm.original_inventory_sector = ce.original_inventory_sector\n",
    "\n",
    "\twhere extract(year from ce.start_time) = 2024\n",
    "\t\tand ce.gas = 'co2e_100yr'\n",
    "        and cb.city_id is not null\n",
    "\n",
    "\tgroup by extract(year from start_time) \n",
    "\t\t, ce.city_id\n",
    "\t\t, cb.name \n",
    "\t\t, cb.corrected_name \n",
    "\t\t, ce.iso3_country\n",
    "\t\t, ca.name \n",
    "        , ca.continent\n",
    "        , ca.eu\n",
    "        , ca.oecd\n",
    "        , ca.unfccc_annex\n",
    "        , ca.developed_un\n",
    "        , ca.em_finance\n",
    "        , ca.g20\n",
    "\t\t, asch.sector\n",
    "\t\t, ce.original_inventory_sector\n",
    "        , itm.activity_is_temporal;\n",
    "            \n",
    "    COPY city_emissions_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "# and ce.original_inventory_sector not in ('forest-land-clearing',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-degradation',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'forest-land-fires',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-forest-land',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-shrubgrass',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'net-wetland',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'removals',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'shrubgrass-fires',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'water-reservoirs',\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t'wetland-fires')\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfuly refreshed city_emissions data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb613882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ Asset Ownership ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/asset_ownership.parquet\"\n",
    "output_path = \"ownership\"\n",
    "\n",
    "# Use DuckDB to write directly from PostgreSQL to Parquet\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE asset_ownership_parquet AS\n",
    "            \n",
    "    SELECT *\n",
    "    FROM postgres_scan('{postgres_url}','public', 'asset_ownership');\n",
    "    \n",
    "    COPY asset_ownership_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed ownership data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ Demographic ------------------------------------\n",
    "\n",
    "parquet_path = \"zzz_landing_zone/demographic.parquet\"\n",
    "output_path = \"demographic\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "print('Running query...')\n",
    "con.execute( f'''\n",
    "\tINSTALL postgres;\n",
    "\tLOAD postgres;\n",
    "\n",
    "\tCREATE TABLE demographic_parquet AS\n",
    "            \n",
    "    select *\n",
    "    from postgres_scan('{postgres_url}', 'public', 'demographic_data')\n",
    "    where version = 'global_pop_2024_CN_1km_R2024B_UA_v1';\n",
    "    \n",
    "    COPY demographic_parquet TO '{parquet_path}' (FORMAT PARQUET);\n",
    "            \n",
    "    ''')\n",
    "\n",
    "con.close()\n",
    "\n",
    "split_or_move_parquet(parquet_path, output_path)\n",
    "\n",
    "print('Successfully refreshed ownership data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data refresh complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
